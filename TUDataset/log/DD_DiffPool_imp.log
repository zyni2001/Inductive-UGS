[92mExp Information:[00m
[92m------------------------------------------------------------------------------------------------------------------------------------------------------[00m
[93mDataset:[DD] | Save Dir:[debug] | Seed:[666][00m
epochs.......................................................................100
get_mask_epochs..............................................................100
score_function........................................................concat_mlp
mask_lr.....................................................................0.01
mask_dim......................................................................64
mask_type....................................................................GCN
save_masker_ckpt...........................................................False
pruning_percent.............................................................0.05
pruning_percent_w............................................................0.0
binary.....................................................................False
dataset.......................................................................DD
max_nodes....................................................................500
folds..........................................................................2
seed.........................................................................666
data_root...................................................................data
save_dir...................................................................debug
batch_size....................................................................32
lr.........................................................................0.001
lr_decay_factor..............................................................0.5
lr_decay_step_size...........................................................500
weight_decay...................................................................0
epoch_select............................................................test_max
n_layers_feat..................................................................1
n_layers_conv..................................................................3
n_layers_fc....................................................................2
hidden.......................................................................128
global_pool..................................................................sum
skip_connection............................................................False
res_branch............................................................BNConvReLU
dropout........................................................................0
edge_norm...................................................................True
with_eval_mode..............................................................True
semi_split....................................................................10
pre_trans...................................................................True
og_url......................................................................True

[92m----------------------------------------------------------------------------------------------------[00m
Downloading https://www.chrsmrrs.com/graphkerneldatasets/DD.zip
Extracting data/DD/DD.zip
Processing...
Skipping a graph with 4152 nodes.
Skipping a graph with 1396 nodes.
Skipping a graph with 503 nodes.
Skipping a graph with 5748 nodes.
Skipping a graph with 697 nodes.
Skipping a graph with 557 nodes.
Skipping a graph with 534 nodes.
Skipping a graph with 620 nodes.
Skipping a graph with 611 nodes.
Skipping a graph with 775 nodes.
Skipping a graph with 540 nodes.
Skipping a graph with 1021 nodes.
Skipping a graph with 504 nodes.
Skipping a graph with 561 nodes.
Skipping a graph with 574 nodes.
Skipping a graph with 534 nodes.
Skipping a graph with 560 nodes.
Skipping a graph with 580 nodes.
Skipping a graph with 729 nodes.
Skipping a graph with 660 nodes.
Skipping a graph with 553 nodes.
Skipping a graph with 510 nodes.
Skipping a graph with 538 nodes.
Skipping a graph with 645 nodes.
Skipping a graph with 2495 nodes.
Skipping a graph with 841 nodes.
Skipping a graph with 540 nodes.
Skipping a graph with 551 nodes.
Skipping a graph with 640 nodes.
Skipping a graph with 721 nodes.
Skipping a graph with 508 nodes.
Skipping a graph with 601 nodes.
Skipping a graph with 504 nodes.
Skipping a graph with 1284 nodes.
Skipping a graph with 545 nodes.
Skipping a graph with 533 nodes.
Skipping a graph with 629 nodes.
Skipping a graph with 803 nodes.
Skipping a graph with 512 nodes.
Skipping a graph with 592 nodes.
Skipping a graph with 504 nodes.
Skipping a graph with 1160 nodes.
Skipping a graph with 571 nodes.
Skipping a graph with 555 nodes.
Skipping a graph with 636 nodes.
Skipping a graph with 639 nodes.
Skipping a graph with 1019 nodes.
Skipping a graph with 664 nodes.
Skipping a graph with 516 nodes.
Skipping a graph with 897 nodes.
Skipping a graph with 1103 nodes.
Skipping a graph with 725 nodes.
Skipping a graph with 616 nodes.
Skipping a graph with 553 nodes.
Skipping a graph with 807 nodes.
Skipping a graph with 525 nodes.
Skipping a graph with 678 nodes.
Skipping a graph with 539 nodes.
Skipping a graph with 723 nodes.
Skipping a graph with 585 nodes.
Skipping a graph with 537 nodes.
Skipping a graph with 508 nodes.
Skipping a graph with 858 nodes.
Skipping a graph with 834 nodes.
Skipping a graph with 727 nodes.
Skipping a graph with 710 nodes.
Skipping a graph with 903 nodes.
Skipping a graph with 623 nodes.
Skipping a graph with 532 nodes.
Skipping a graph with 655 nodes.
Skipping a graph with 550 nodes.
Skipping a graph with 514 nodes.
Skipping a graph with 1704 nodes.
Skipping a graph with 710 nodes.
Skipping a graph with 618 nodes.
Skipping a graph with 737 nodes.
Skipping a graph with 605 nodes.
Skipping a graph with 576 nodes.
Skipping a graph with 839 nodes.
Skipping a graph with 869 nodes.
Skipping a graph with 565 nodes.
Skipping a graph with 522 nodes.
Skipping a graph with 623 nodes.
Skipping a graph with 570 nodes.
Skipping a graph with 522 nodes.
Skipping a graph with 684 nodes.
Skipping a graph with 779 nodes.
Skipping a graph with 561 nodes.
Skipping a graph with 679 nodes.
Skipping a graph with 523 nodes.
Skipping a graph with 534 nodes.
Skipping a graph with 753 nodes.
Skipping a graph with 725 nodes.
Skipping a graph with 560 nodes.
Skipping a graph with 691 nodes.
Skipping a graph with 578 nodes.
Skipping a graph with 684 nodes.
Skipping a graph with 685 nodes.
Skipping a graph with 560 nodes.
Skipping a graph with 553 nodes.
Skipping a graph with 582 nodes.
Skipping a graph with 546 nodes.
Skipping a graph with 570 nodes.
Skipping a graph with 508 nodes.
Skipping a graph with 569 nodes.
Skipping a graph with 530 nodes.
Skipping a graph with 576 nodes.
Skipping a graph with 517 nodes.
Skipping a graph with 589 nodes.
Skipping a graph with 600 nodes.
Skipping a graph with 743 nodes.
Skipping a graph with 523 nodes.
Skipping a graph with 573 nodes.
Skipping a graph with 707 nodes.
Skipping a graph with 558 nodes.
Skipping a graph with 543 nodes.
Skipping a graph with 573 nodes.
Skipping a graph with 891 nodes.
/home/zhiyu/anaconda3/envs/gnn-infer/lib/python3.10/site-packages/torch_geometric/data/in_memory_dataset.py:157: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
Done!
/home/zhiyu/anaconda3/envs/gnn-infer/lib/python3.10/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead
  warnings.warn(out)
INFO: Weight Sparsity [0.0000%] 
(Train IMP:[1] fold:[0] spa:[0.00%] spw:[0.00%]) Epoch:[1/100] Loss:[0.5587] Train:[72.64] Test:[44.15] | Best Test:[44.15] at Epoch:[1] | 0-0.2:[25.30%] 0.2-0.4:[10.22%] 0.4-0.6:[15.87%] 0.6-0.8:[12.82%] 0.8-1.0:[35.79%]
(Train IMP:[1] fold:[0] spa:[0.00%] spw:[0.00%]) Epoch:[2/100] Loss:[0.5264] Train:[76.60] Test:[55.47] | Best Test:[55.47] at Epoch:[2] | 0-0.2:[39.57%] 0.2-0.4:[3.32%] 0.4-0.6:[2.82%] 0.6-0.8:[3.50%] 0.8-1.0:[50.79%]
(Train IMP:[1] fold:[0] spa:[0.00%] spw:[0.00%]) Epoch:[3/100] Loss:[0.5030] Train:[77.55] Test:[74.91] | Best Test:[74.91] at Epoch:[3] | 0-0.2:[42.15%] 0.2-0.4:[2.33%] 0.4-0.6:[1.94%] 0.6-0.8:[2.42%] 0.8-1.0:[51.16%]
(Train IMP:[1] fold:[0] spa:[0.00%] spw:[0.00%]) Epoch:[4/100] Loss:[0.4515] Train:[80.00] Test:[69.81] | Best Test:[74.91] at Epoch:[3] | 0-0.2:[35.43%] 0.2-0.4:[1.78%] 0.4-0.6:[1.49%] 0.6-0.8:[1.87%] 0.8-1.0:[59.42%]
(Train IMP:[1] fold:[0] spa:[0.00%] spw:[0.00%]) Epoch:[5/100] Loss:[0.4536] Train:[80.00] Test:[70.19] | Best Test:[74.91] at Epoch:[3] | 0-0.2:[39.67%] 0.2-0.4:[2.30%] 0.4-0.6:[1.96%] 0.6-0.8:[2.45%] 0.8-1.0:[53.63%]
(Train IMP:[1] fold:[0] spa:[0.00%] spw:[0.00%]) Epoch:[6/100] Loss:[0.4180] Train:[80.75] Test:[45.66] | Best Test:[74.91] at Epoch:[3] | 0-0.2:[41.12%] 0.2-0.4:[2.33%] 0.4-0.6:[2.05%] 0.6-0.8:[2.64%] 0.8-1.0:[51.87%]
(Train IMP:[1] fold:[0] spa:[0.00%] spw:[0.00%]) Epoch:[7/100] Loss:[0.3798] Train:[82.26] Test:[69.06] | Best Test:[74.91] at Epoch:[3] | 0-0.2:[40.70%] 0.2-0.4:[1.42%] 0.4-0.6:[1.24%] 0.6-0.8:[1.50%] 0.8-1.0:[55.15%]
(Train IMP:[1] fold:[0] spa:[0.00%] spw:[0.00%]) Epoch:[8/100] Loss:[0.3480] Train:[84.91] Test:[69.81] | Best Test:[74.91] at Epoch:[3] | 0-0.2:[34.33%] 0.2-0.4:[1.07%] 0.4-0.6:[0.94%] 0.6-0.8:[1.16%] 0.8-1.0:[62.50%]
(Train IMP:[1] fold:[0] spa:[0.00%] spw:[0.00%]) Epoch:[9/100] Loss:[0.3286] Train:[87.36] Test:[67.17] | Best Test:[74.91] at Epoch:[3] | 0-0.2:[27.77%] 0.2-0.4:[0.73%] 0.4-0.6:[0.61%] 0.6-0.8:[0.77%] 0.8-1.0:[70.12%]
(Train IMP:[1] fold:[0] spa:[0.00%] spw:[0.00%]) Epoch:[10/100] Loss:[0.3062] Train:[87.36] Test:[69.62] | Best Test:[74.91] at Epoch:[3] | 0-0.2:[27.64%] 0.2-0.4:[0.59%] 0.4-0.6:[0.52%] 0.6-0.8:[0.64%] 0.8-1.0:[70.62%]
(Train IMP:[1] fold:[0] spa:[0.00%] spw:[0.00%]) Epoch:[11/100] Loss:[0.2917] Train:[87.92] Test:[42.64] | Best Test:[74.91] at Epoch:[3] | 0-0.2:[27.14%] 0.2-0.4:[0.55%] 0.4-0.6:[0.46%] 0.6-0.8:[0.60%] 0.8-1.0:[71.26%]
(Train IMP:[1] fold:[0] spa:[0.00%] spw:[0.00%]) Epoch:[12/100] Loss:[0.2501] Train:[90.75] Test:[52.64] | Best Test:[74.91] at Epoch:[3] | 0-0.2:[23.06%] 0.2-0.4:[0.40%] 0.4-0.6:[0.35%] 0.6-0.8:[0.44%] 0.8-1.0:[75.75%]
(Train IMP:[1] fold:[0] spa:[0.00%] spw:[0.00%]) Epoch:[13/100] Loss:[0.2218] Train:[92.08] Test:[71.13] | Best Test:[74.91] at Epoch:[3] | 0-0.2:[24.03%] 0.2-0.4:[0.42%] 0.4-0.6:[0.36%] 0.6-0.8:[0.47%] 0.8-1.0:[74.72%]
(Train IMP:[1] fold:[0] spa:[0.00%] spw:[0.00%]) Epoch:[14/100] Loss:[0.2015] Train:[92.45] Test:[73.77] | Best Test:[74.91] at Epoch:[3] | 0-0.2:[20.03%] 0.2-0.4:[0.35%] 0.4-0.6:[0.30%] 0.6-0.8:[0.36%] 0.8-1.0:[78.96%]
(Train IMP:[1] fold:[0] spa:[0.00%] spw:[0.00%]) Epoch:[15/100] Loss:[0.2307] Train:[91.51] Test:[41.70] | Best Test:[74.91] at Epoch:[3] | 0-0.2:[21.46%] 0.2-0.4:[0.39%] 0.4-0.6:[0.32%] 0.6-0.8:[0.42%] 0.8-1.0:[77.41%]
(Train IMP:[1] fold:[0] spa:[0.00%] spw:[0.00%]) Epoch:[16/100] Loss:[0.2353] Train:[91.70] Test:[62.45] | Best Test:[74.91] at Epoch:[3] | 0-0.2:[24.82%] 0.2-0.4:[0.41%] 0.4-0.6:[0.34%] 0.6-0.8:[0.41%] 0.8-1.0:[74.01%]
(Train IMP:[1] fold:[0] spa:[0.00%] spw:[0.00%]) Epoch:[17/100] Loss:[0.1958] Train:[92.45] Test:[74.15] | Best Test:[74.91] at Epoch:[3] | 0-0.2:[23.26%] 0.2-0.4:[0.32%] 0.4-0.6:[0.29%] 0.6-0.8:[0.34%] 0.8-1.0:[75.79%]
(Train IMP:[1] fold:[0] spa:[0.00%] spw:[0.00%]) Epoch:[18/100] Loss:[0.1664] Train:[93.58] Test:[43.77] | Best Test:[74.91] at Epoch:[3] | 0-0.2:[23.56%] 0.2-0.4:[0.27%] 0.4-0.6:[0.23%] 0.6-0.8:[0.28%] 0.8-1.0:[75.66%]
(Train IMP:[1] fold:[0] spa:[0.00%] spw:[0.00%]) Epoch:[19/100] Loss:[0.1379] Train:[94.53] Test:[70.38] | Best Test:[74.91] at Epoch:[3] | 0-0.2:[23.82%] 0.2-0.4:[0.27%] 0.4-0.6:[0.23%] 0.6-0.8:[0.26%] 0.8-1.0:[75.42%]
(Train IMP:[1] fold:[0] spa:[0.00%] spw:[0.00%]) Epoch:[20/100] Loss:[0.1146] Train:[96.04] Test:[70.00] | Best Test:[74.91] at Epoch:[3] | 0-0.2:[17.74%] 0.2-0.4:[0.20%] 0.4-0.6:[0.17%] 0.6-0.8:[0.22%] 0.8-1.0:[81.68%]
(Train IMP:[1] fold:[0] spa:[0.00%] spw:[0.00%]) Epoch:[21/100] Loss:[0.0967] Train:[96.60] Test:[71.89] | Best Test:[74.91] at Epoch:[3] | 0-0.2:[16.17%] 0.2-0.4:[0.17%] 0.4-0.6:[0.14%] 0.6-0.8:[0.18%] 0.8-1.0:[83.34%]
(Train IMP:[1] fold:[0] spa:[0.00%] spw:[0.00%]) Epoch:[22/100] Loss:[0.1103] Train:[96.04] Test:[73.77] | Best Test:[74.91] at Epoch:[3] | 0-0.2:[12.56%] 0.2-0.4:[0.17%] 0.4-0.6:[0.15%] 0.6-0.8:[0.17%] 0.8-1.0:[86.95%]
(Train IMP:[1] fold:[0] spa:[0.00%] spw:[0.00%]) Epoch:[23/100] Loss:[0.1295] Train:[94.15] Test:[74.15] | Best Test:[74.91] at Epoch:[3] | 0-0.2:[11.46%] 0.2-0.4:[0.12%] 0.4-0.6:[0.10%] 0.6-0.8:[0.13%] 0.8-1.0:[88.19%]
(Train IMP:[1] fold:[0] spa:[0.00%] spw:[0.00%]) Epoch:[24/100] Loss:[0.1448] Train:[95.09] Test:[63.77] | Best Test:[74.91] at Epoch:[3] | 0-0.2:[16.66%] 0.2-0.4:[0.15%] 0.4-0.6:[0.12%] 0.6-0.8:[0.14%] 0.8-1.0:[82.93%]
(Train IMP:[1] fold:[0] spa:[0.00%] spw:[0.00%]) Epoch:[25/100] Loss:[0.1093] Train:[96.23] Test:[75.28] | Best Test:[75.28] at Epoch:[25] | 0-0.2:[18.09%] 0.2-0.4:[0.17%] 0.4-0.6:[0.14%] 0.6-0.8:[0.17%] 0.8-1.0:[81.43%]
(Train IMP:[1] fold:[0] spa:[0.00%] spw:[0.00%]) Epoch:[26/100] Loss:[0.1181] Train:[95.66] Test:[57.55] | Best Test:[75.28] at Epoch:[25] | 0-0.2:[17.71%] 0.2-0.4:[0.14%] 0.4-0.6:[0.12%] 0.6-0.8:[0.15%] 0.8-1.0:[81.87%]
(Train IMP:[1] fold:[0] spa:[0.00%] spw:[0.00%]) Epoch:[27/100] Loss:[0.1620] Train:[94.15] Test:[72.45] | Best Test:[75.28] at Epoch:[25] | 0-0.2:[17.63%] 0.2-0.4:[0.10%] 0.4-0.6:[0.09%] 0.6-0.8:[0.11%] 0.8-1.0:[82.07%]
(Train IMP:[1] fold:[0] spa:[0.00%] spw:[0.00%]) Epoch:[28/100] Loss:[0.0879] Train:[96.98] Test:[73.58] | Best Test:[75.28] at Epoch:[25] | 0-0.2:[17.48%] 0.2-0.4:[0.10%] 0.4-0.6:[0.08%] 0.6-0.8:[0.11%] 0.8-1.0:[82.23%]
(Train IMP:[1] fold:[0] spa:[0.00%] spw:[0.00%]) Epoch:[29/100] Loss:[0.0934] Train:[96.79] Test:[71.89] | Best Test:[75.28] at Epoch:[25] | 0-0.2:[20.79%] 0.2-0.4:[0.11%] 0.4-0.6:[0.09%] 0.6-0.8:[0.11%] 0.8-1.0:[78.90%]
(Train IMP:[1] fold:[0] spa:[0.00%] spw:[0.00%]) Epoch:[30/100] Loss:[0.0872] Train:[96.98] Test:[72.26] | Best Test:[75.28] at Epoch:[25] | 0-0.2:[23.38%] 0.2-0.4:[0.14%] 0.4-0.6:[0.11%] 0.6-0.8:[0.15%] 0.8-1.0:[76.22%]
(Train IMP:[1] fold:[0] spa:[0.00%] spw:[0.00%]) Epoch:[31/100] Loss:[0.1294] Train:[94.91] Test:[71.32] | Best Test:[75.28] at Epoch:[25] | 0-0.2:[24.24%] 0.2-0.4:[0.15%] 0.4-0.6:[0.12%] 0.6-0.8:[0.14%] 0.8-1.0:[75.35%]
(Train IMP:[1] fold:[0] spa:[0.00%] spw:[0.00%]) Epoch:[32/100] Loss:[0.1235] Train:[94.91] Test:[71.13] | Best Test:[75.28] at Epoch:[25] | 0-0.2:[22.61%] 0.2-0.4:[0.14%] 0.4-0.6:[0.12%] 0.6-0.8:[0.13%] 0.8-1.0:[77.00%]
(Train IMP:[1] fold:[0] spa:[0.00%] spw:[0.00%]) Epoch:[33/100] Loss:[0.1180] Train:[95.28] Test:[71.51] | Best Test:[75.28] at Epoch:[25] | 0-0.2:[23.30%] 0.2-0.4:[0.13%] 0.4-0.6:[0.10%] 0.6-0.8:[0.13%] 0.8-1.0:[76.34%]
(Train IMP:[1] fold:[0] spa:[0.00%] spw:[0.00%]) Epoch:[34/100] Loss:[0.0861] Train:[97.36] Test:[72.08] | Best Test:[75.28] at Epoch:[25] | 0-0.2:[24.36%] 0.2-0.4:[0.13%] 0.4-0.6:[0.11%] 0.6-0.8:[0.13%] 0.8-1.0:[75.26%]
(Train IMP:[1] fold:[0] spa:[0.00%] spw:[0.00%]) Epoch:[35/100] Loss:[0.1057] Train:[95.66] Test:[73.02] | Best Test:[75.28] at Epoch:[25] | 0-0.2:[22.15%] 0.2-0.4:[0.13%] 0.4-0.6:[0.10%] 0.6-0.8:[0.12%] 0.8-1.0:[77.49%]
(Train IMP:[1] fold:[0] spa:[0.00%] spw:[0.00%]) Epoch:[36/100] Loss:[0.0868] Train:[97.17] Test:[62.08] | Best Test:[75.28] at Epoch:[25] | 0-0.2:[17.88%] 0.2-0.4:[0.11%] 0.4-0.6:[0.09%] 0.6-0.8:[0.11%] 0.8-1.0:[81.82%]
(Train IMP:[1] fold:[0] spa:[0.00%] spw:[0.00%]) Epoch:[37/100] Loss:[0.0441] Train:[99.06] Test:[68.30] | Best Test:[75.28] at Epoch:[25] | 0-0.2:[16.88%] 0.2-0.4:[0.11%] 0.4-0.6:[0.09%] 0.6-0.8:[0.10%] 0.8-1.0:[82.82%]
(Train IMP:[1] fold:[0] spa:[0.00%] spw:[0.00%]) Epoch:[38/100] Loss:[0.0868] Train:[97.92] Test:[74.72] | Best Test:[75.28] at Epoch:[25] | 0-0.2:[14.14%] 0.2-0.4:[0.09%] 0.4-0.6:[0.08%] 0.6-0.8:[0.10%] 0.8-1.0:[85.58%]
(Train IMP:[1] fold:[0] spa:[0.00%] spw:[0.00%]) Epoch:[39/100] Loss:[0.0620] Train:[97.55] Test:[70.19] | Best Test:[75.28] at Epoch:[25] | 0-0.2:[11.13%] 0.2-0.4:[0.09%] 0.4-0.6:[0.08%] 0.6-0.8:[0.09%] 0.8-1.0:[88.61%]
(Train IMP:[1] fold:[0] spa:[0.00%] spw:[0.00%]) Epoch:[40/100] Loss:[0.0479] Train:[98.49] Test:[74.91] | Best Test:[75.28] at Epoch:[25] | 0-0.2:[11.19%] 0.2-0.4:[0.07%] 0.4-0.6:[0.05%] 0.6-0.8:[0.07%] 0.8-1.0:[88.62%]
(Train IMP:[1] fold:[0] spa:[0.00%] spw:[0.00%]) Epoch:[41/100] Loss:[0.1073] Train:[95.47] Test:[71.51] | Best Test:[75.28] at Epoch:[25] | 0-0.2:[10.68%] 0.2-0.4:[0.07%] 0.4-0.6:[0.05%] 0.6-0.8:[0.07%] 0.8-1.0:[89.13%]
(Train IMP:[1] fold:[0] spa:[0.00%] spw:[0.00%]) Epoch:[42/100] Loss:[0.0879] Train:[96.98] Test:[62.83] | Best Test:[75.28] at Epoch:[25] | 0-0.2:[9.38%] 0.2-0.4:[0.05%] 0.4-0.6:[0.05%] 0.6-0.8:[0.06%] 0.8-1.0:[90.46%]
(Train IMP:[1] fold:[0] spa:[0.00%] spw:[0.00%]) Epoch:[43/100] Loss:[0.0823] Train:[97.36] Test:[71.32] | Best Test:[75.28] at Epoch:[25] | 0-0.2:[10.37%] 0.2-0.4:[0.08%] 0.4-0.6:[0.07%] 0.6-0.8:[0.08%] 0.8-1.0:[89.40%]
(Train IMP:[1] fold:[0] spa:[0.00%] spw:[0.00%]) Epoch:[44/100] Loss:[0.0443] Train:[98.49] Test:[70.75] | Best Test:[75.28] at Epoch:[25] | 0-0.2:[10.77%] 0.2-0.4:[0.08%] 0.4-0.6:[0.07%] 0.6-0.8:[0.09%] 0.8-1.0:[88.99%]
(Train IMP:[1] fold:[0] spa:[0.00%] spw:[0.00%]) Epoch:[45/100] Loss:[0.0833] Train:[96.42] Test:[70.19] | Best Test:[75.28] at Epoch:[25] | 0-0.2:[9.32%] 0.2-0.4:[0.08%] 0.4-0.6:[0.06%] 0.6-0.8:[0.08%] 0.8-1.0:[90.46%]
(Train IMP:[1] fold:[0] spa:[0.00%] spw:[0.00%]) Epoch:[46/100] Loss:[0.0870] Train:[97.17] Test:[74.53] | Best Test:[75.28] at Epoch:[25] | 0-0.2:[5.98%] 0.2-0.4:[0.06%] 0.4-0.6:[0.04%] 0.6-0.8:[0.05%] 0.8-1.0:[93.87%]
(Train IMP:[1] fold:[0] spa:[0.00%] spw:[0.00%]) Epoch:[47/100] Loss:[0.0459] Train:[98.68] Test:[69.81] | Best Test:[75.28] at Epoch:[25] | 0-0.2:[6.08%] 0.2-0.4:[0.04%] 0.4-0.6:[0.04%] 0.6-0.8:[0.05%] 0.8-1.0:[93.79%]
(Train IMP:[1] fold:[0] spa:[0.00%] spw:[0.00%]) Epoch:[48/100] Loss:[0.0374] Train:[98.68] Test:[75.66] | Best Test:[75.66] at Epoch:[48] | 0-0.2:[6.19%] 0.2-0.4:[0.04%] 0.4-0.6:[0.04%] 0.6-0.8:[0.04%] 0.8-1.0:[93.69%]
(Train IMP:[1] fold:[0] spa:[0.00%] spw:[0.00%]) Epoch:[49/100] Loss:[0.0494] Train:[98.30] Test:[74.91] | Best Test:[75.66] at Epoch:[48] | 0-0.2:[5.75%] 0.2-0.4:[0.04%] 0.4-0.6:[0.03%] 0.6-0.8:[0.04%] 0.8-1.0:[94.14%]
(Train IMP:[1] fold:[0] spa:[0.00%] spw:[0.00%]) Epoch:[50/100] Loss:[0.0374] Train:[98.87] Test:[67.92] | Best Test:[75.66] at Epoch:[48] | 0-0.2:[6.14%] 0.2-0.4:[0.04%] 0.4-0.6:[0.04%] 0.6-0.8:[0.04%] 0.8-1.0:[93.73%]
(Train IMP:[1] fold:[0] spa:[0.00%] spw:[0.00%]) Epoch:[51/100] Loss:[0.0560] Train:[97.92] Test:[73.96] | Best Test:[75.66] at Epoch:[48] | 0-0.2:[7.37%] 0.2-0.4:[0.05%] 0.4-0.6:[0.04%] 0.6-0.8:[0.05%] 0.8-1.0:[92.49%]
(Train IMP:[1] fold:[0] spa:[0.00%] spw:[0.00%]) Epoch:[52/100] Loss:[0.0200] Train:[99.43] Test:[73.02] | Best Test:[75.66] at Epoch:[48] | 0-0.2:[7.78%] 0.2-0.4:[0.05%] 0.4-0.6:[0.04%] 0.6-0.8:[0.05%] 0.8-1.0:[92.08%]
(Train IMP:[1] fold:[0] spa:[0.00%] spw:[0.00%]) Epoch:[53/100] Loss:[0.0593] Train:[97.36] Test:[74.72] | Best Test:[75.66] at Epoch:[48] | 0-0.2:[6.43%] 0.2-0.4:[0.04%] 0.4-0.6:[0.03%] 0.6-0.8:[0.04%] 0.8-1.0:[93.46%]
(Train IMP:[1] fold:[0] spa:[0.00%] spw:[0.00%]) Epoch:[54/100] Loss:[0.0702] Train:[97.36] Test:[72.83] | Best Test:[75.66] at Epoch:[48] | 0-0.2:[6.14%] 0.2-0.4:[0.06%] 0.4-0.6:[0.04%] 0.6-0.8:[0.05%] 0.8-1.0:[93.70%]
(Train IMP:[1] fold:[0] spa:[0.00%] spw:[0.00%]) Epoch:[55/100] Loss:[0.0944] Train:[96.60] Test:[65.47] | Best Test:[75.66] at Epoch:[48] | 0-0.2:[6.13%] 0.2-0.4:[0.05%] 0.4-0.6:[0.05%] 0.6-0.8:[0.06%] 0.8-1.0:[93.71%]
(Train IMP:[1] fold:[0] spa:[0.00%] spw:[0.00%]) Epoch:[56/100] Loss:[0.0555] Train:[97.92] Test:[74.91] | Best Test:[75.66] at Epoch:[48] | 0-0.2:[5.36%] 0.2-0.4:[0.06%] 0.4-0.6:[0.05%] 0.6-0.8:[0.06%] 0.8-1.0:[94.47%]
(Train IMP:[1] fold:[0] spa:[0.00%] spw:[0.00%]) Epoch:[57/100] Loss:[0.0256] Train:[99.43] Test:[73.77] | Best Test:[75.66] at Epoch:[48] | 0-0.2:[3.74%] 0.2-0.4:[0.06%] 0.4-0.6:[0.04%] 0.6-0.8:[0.05%] 0.8-1.0:[96.11%]
(Train IMP:[1] fold:[0] spa:[0.00%] spw:[0.00%]) Epoch:[58/100] Loss:[0.0218] Train:[99.62] Test:[73.96] | Best Test:[75.66] at Epoch:[48] | 0-0.2:[3.37%] 0.2-0.4:[0.05%] 0.4-0.6:[0.04%] 0.6-0.8:[0.06%] 0.8-1.0:[96.48%]
(Train IMP:[1] fold:[0] spa:[0.00%] spw:[0.00%]) Epoch:[59/100] Loss:[0.0193] Train:[99.62] Test:[72.26] | Best Test:[75.66] at Epoch:[48] | 0-0.2:[4.43%] 0.2-0.4:[0.06%] 0.4-0.6:[0.05%] 0.6-0.8:[0.06%] 0.8-1.0:[95.41%]
(Train IMP:[1] fold:[0] spa:[0.00%] spw:[0.00%]) Epoch:[60/100] Loss:[0.0372] Train:[98.49] Test:[68.68] | Best Test:[75.66] at Epoch:[48] | 0-0.2:[4.39%] 0.2-0.4:[0.05%] 0.4-0.6:[0.04%] 0.6-0.8:[0.05%] 0.8-1.0:[95.47%]
(Train IMP:[1] fold:[0] spa:[0.00%] spw:[0.00%]) Epoch:[61/100] Loss:[0.0375] Train:[98.30] Test:[73.77] | Best Test:[75.66] at Epoch:[48] | 0-0.2:[4.04%] 0.2-0.4:[0.05%] 0.4-0.6:[0.04%] 0.6-0.8:[0.05%] 0.8-1.0:[95.82%]
(Train IMP:[1] fold:[0] spa:[0.00%] spw:[0.00%]) Epoch:[62/100] Loss:[0.0349] Train:[98.87] Test:[55.85] | Best Test:[75.66] at Epoch:[48] | 0-0.2:[3.30%] 0.2-0.4:[0.11%] 0.4-0.6:[0.09%] 0.6-0.8:[0.13%] 0.8-1.0:[96.37%]
(Train IMP:[1] fold:[0] spa:[0.00%] spw:[0.00%]) Epoch:[63/100] Loss:[0.0949] Train:[97.36] Test:[69.25] | Best Test:[75.66] at Epoch:[48] | 0-0.2:[4.41%] 0.2-0.4:[0.33%] 0.4-0.6:[0.30%] 0.6-0.8:[0.37%] 0.8-1.0:[94.59%]
(Train IMP:[1] fold:[0] spa:[0.00%] spw:[0.00%]) Epoch:[64/100] Loss:[0.0221] Train:[99.81] Test:[73.77] | Best Test:[75.66] at Epoch:[48] | 0-0.2:[1.20%] 0.2-0.4:[0.01%] 0.4-0.6:[0.01%] 0.6-0.8:[0.02%] 0.8-1.0:[98.76%]
(Train IMP:[1] fold:[0] spa:[0.00%] spw:[0.00%]) Epoch:[65/100] Loss:[0.0122] Train:[99.81] Test:[70.75] | Best Test:[75.66] at Epoch:[48] | 0-0.2:[0.90%] 0.2-0.4:[0.01%] 0.4-0.6:[0.01%] 0.6-0.8:[0.02%] 0.8-1.0:[99.06%]
(Train IMP:[1] fold:[0] spa:[0.00%] spw:[0.00%]) Epoch:[66/100] Loss:[0.0232] Train:[99.06] Test:[74.53] | Best Test:[75.66] at Epoch:[48] | 0-0.2:[0.18%] 0.2-0.4:[0.00%] 0.4-0.6:[0.00%] 0.6-0.8:[0.00%] 0.8-1.0:[99.81%]
(Train IMP:[1] fold:[0] spa:[0.00%] spw:[0.00%]) Epoch:[67/100] Loss:[0.0535] Train:[98.11] Test:[59.06] | Best Test:[75.66] at Epoch:[48] | 0-0.2:[0.00%] 0.2-0.4:[0.00%] 0.4-0.6:[0.00%] 0.6-0.8:[0.00%] 0.8-1.0:[100.00%]
(Train IMP:[1] fold:[0] spa:[0.00%] spw:[0.00%]) Epoch:[68/100] Loss:[0.0627] Train:[98.11] Test:[44.15] | Best Test:[75.66] at Epoch:[48] | 0-0.2:[0.00%] 0.2-0.4:[0.00%] 0.4-0.6:[0.00%] 0.6-0.8:[0.00%] 0.8-1.0:[100.00%]
(Train IMP:[1] fold:[0] spa:[0.00%] spw:[0.00%]) Epoch:[69/100] Loss:[0.0612] Train:[97.17] Test:[44.34] | Best Test:[75.66] at Epoch:[48] | 0-0.2:[0.00%] 0.2-0.4:[0.00%] 0.4-0.6:[0.00%] 0.6-0.8:[0.00%] 0.8-1.0:[100.00%]
(Train IMP:[1] fold:[0] spa:[0.00%] spw:[0.00%]) Epoch:[70/100] Loss:[0.0465] Train:[97.92] Test:[46.23] | Best Test:[75.66] at Epoch:[48] | 0-0.2:[0.00%] 0.2-0.4:[0.00%] 0.4-0.6:[0.00%] 0.6-0.8:[0.00%] 0.8-1.0:[100.00%]
(Train IMP:[1] fold:[0] spa:[0.00%] spw:[0.00%]) Epoch:[71/100] Loss:[0.0381] Train:[98.87] Test:[53.77] | Best Test:[75.66] at Epoch:[48] | 0-0.2:[0.00%] 0.2-0.4:[0.00%] 0.4-0.6:[0.00%] 0.6-0.8:[0.00%] 0.8-1.0:[100.00%]
(Train IMP:[1] fold:[0] spa:[0.00%] spw:[0.00%]) Epoch:[72/100] Loss:[0.0204] Train:[98.87] Test:[62.08] | Best Test:[75.66] at Epoch:[48] | 0-0.2:[0.00%] 0.2-0.4:[0.00%] 0.4-0.6:[0.00%] 0.6-0.8:[0.00%] 0.8-1.0:[100.00%]
(Train IMP:[1] fold:[0] spa:[0.00%] spw:[0.00%]) Epoch:[73/100] Loss:[0.0145] Train:[99.43] Test:[63.77] | Best Test:[75.66] at Epoch:[48] | 0-0.2:[0.00%] 0.2-0.4:[0.00%] 0.4-0.6:[0.00%] 0.6-0.8:[0.00%] 0.8-1.0:[100.00%]
(Train IMP:[1] fold:[0] spa:[0.00%] spw:[0.00%]) Epoch:[74/100] Loss:[0.0400] Train:[99.06] Test:[65.85] | Best Test:[75.66] at Epoch:[48] | 0-0.2:[0.00%] 0.2-0.4:[0.00%] 0.4-0.6:[0.00%] 0.6-0.8:[0.00%] 0.8-1.0:[100.00%]
(Train IMP:[1] fold:[0] spa:[0.00%] spw:[0.00%]) Epoch:[75/100] Loss:[0.0296] Train:[99.43] Test:[67.17] | Best Test:[75.66] at Epoch:[48] | 0-0.2:[0.00%] 0.2-0.4:[0.00%] 0.4-0.6:[0.00%] 0.6-0.8:[0.00%] 0.8-1.0:[100.00%]
(Train IMP:[1] fold:[0] spa:[0.00%] spw:[0.00%]) Epoch:[76/100] Loss:[0.0400] Train:[98.87] Test:[71.13] | Best Test:[75.66] at Epoch:[48] | 0-0.2:[0.00%] 0.2-0.4:[0.00%] 0.4-0.6:[0.00%] 0.6-0.8:[0.00%] 0.8-1.0:[100.00%]
(Train IMP:[1] fold:[0] spa:[0.00%] spw:[0.00%]) Epoch:[77/100] Loss:[0.0406] Train:[98.49] Test:[59.43] | Best Test:[75.66] at Epoch:[48] | 0-0.2:[0.00%] 0.2-0.4:[0.00%] 0.4-0.6:[0.00%] 0.6-0.8:[0.00%] 0.8-1.0:[100.00%]
(Train IMP:[1] fold:[0] spa:[0.00%] spw:[0.00%]) Epoch:[78/100] Loss:[0.0469] Train:[98.30] Test:[44.72] | Best Test:[75.66] at Epoch:[48] | 0-0.2:[0.00%] 0.2-0.4:[0.00%] 0.4-0.6:[0.00%] 0.6-0.8:[0.00%] 0.8-1.0:[100.00%]
(Train IMP:[1] fold:[0] spa:[0.00%] spw:[0.00%]) Epoch:[79/100] Loss:[0.0299] Train:[99.43] Test:[52.64] | Best Test:[75.66] at Epoch:[48] | 0-0.2:[0.00%] 0.2-0.4:[0.00%] 0.4-0.6:[0.00%] 0.6-0.8:[0.00%] 0.8-1.0:[100.00%]
(Train IMP:[1] fold:[0] spa:[0.00%] spw:[0.00%]) Epoch:[80/100] Loss:[0.0158] Train:[99.43] Test:[61.70] | Best Test:[75.66] at Epoch:[48] | 0-0.2:[0.00%] 0.2-0.4:[0.00%] 0.4-0.6:[0.00%] 0.6-0.8:[0.00%] 0.8-1.0:[100.00%]
(Train IMP:[1] fold:[0] spa:[0.00%] spw:[0.00%]) Epoch:[81/100] Loss:[0.0064] Train:[99.81] Test:[58.68] | Best Test:[75.66] at Epoch:[48] | 0-0.2:[0.00%] 0.2-0.4:[0.00%] 0.4-0.6:[0.00%] 0.6-0.8:[0.00%] 0.8-1.0:[100.00%]
(Train IMP:[1] fold:[0] spa:[0.00%] spw:[0.00%]) Epoch:[82/100] Loss:[0.0033] Train:[100.00] Test:[62.26] | Best Test:[75.66] at Epoch:[48] | 0-0.2:[0.00%] 0.2-0.4:[0.00%] 0.4-0.6:[0.00%] 0.6-0.8:[0.00%] 0.8-1.0:[100.00%]
(Train IMP:[1] fold:[0] spa:[0.00%] spw:[0.00%]) Epoch:[83/100] Loss:[0.0299] Train:[99.25] Test:[61.89] | Best Test:[75.66] at Epoch:[48] | 0-0.2:[0.00%] 0.2-0.4:[0.00%] 0.4-0.6:[0.00%] 0.6-0.8:[0.00%] 0.8-1.0:[100.00%]
(Train IMP:[1] fold:[0] spa:[0.00%] spw:[0.00%]) Epoch:[84/100] Loss:[0.0349] Train:[98.87] Test:[49.06] | Best Test:[75.66] at Epoch:[48] | 0-0.2:[0.00%] 0.2-0.4:[0.00%] 0.4-0.6:[0.00%] 0.6-0.8:[0.00%] 0.8-1.0:[100.00%]
(Train IMP:[1] fold:[0] spa:[0.00%] spw:[0.00%]) Epoch:[85/100] Loss:[0.0588] Train:[98.11] Test:[65.09] | Best Test:[75.66] at Epoch:[48] | 0-0.2:[0.00%] 0.2-0.4:[0.00%] 0.4-0.6:[0.00%] 0.6-0.8:[0.00%] 0.8-1.0:[100.00%]
(Train IMP:[1] fold:[0] spa:[0.00%] spw:[0.00%]) Epoch:[86/100] Loss:[0.0266] Train:[98.87] Test:[71.32] | Best Test:[75.66] at Epoch:[48] | 0-0.2:[0.00%] 0.2-0.4:[0.00%] 0.4-0.6:[0.00%] 0.6-0.8:[0.00%] 0.8-1.0:[100.00%]
(Train IMP:[1] fold:[0] spa:[0.00%] spw:[0.00%]) Epoch:[87/100] Loss:[0.0450] Train:[98.11] Test:[75.28] | Best Test:[75.66] at Epoch:[48] | 0-0.2:[0.00%] 0.2-0.4:[0.00%] 0.4-0.6:[0.00%] 0.6-0.8:[0.00%] 0.8-1.0:[100.00%]
(Train IMP:[1] fold:[0] spa:[0.00%] spw:[0.00%]) Epoch:[88/100] Loss:[0.0611] Train:[97.55] Test:[46.23] | Best Test:[75.66] at Epoch:[48] | 0-0.2:[0.00%] 0.2-0.4:[0.00%] 0.4-0.6:[0.00%] 0.6-0.8:[0.00%] 0.8-1.0:[100.00%]
(Train IMP:[1] fold:[0] spa:[0.00%] spw:[0.00%]) Epoch:[89/100] Loss:[0.0209] Train:[99.06] Test:[67.55] | Best Test:[75.66] at Epoch:[48] | 0-0.2:[0.00%] 0.2-0.4:[0.00%] 0.4-0.6:[0.00%] 0.6-0.8:[0.00%] 0.8-1.0:[100.00%]
(Train IMP:[1] fold:[0] spa:[0.00%] spw:[0.00%]) Epoch:[90/100] Loss:[0.0149] Train:[99.62] Test:[66.79] | Best Test:[75.66] at Epoch:[48] | 0-0.2:[0.00%] 0.2-0.4:[0.00%] 0.4-0.6:[0.00%] 0.6-0.8:[0.00%] 0.8-1.0:[100.00%]
(Train IMP:[1] fold:[0] spa:[0.00%] spw:[0.00%]) Epoch:[91/100] Loss:[0.0166] Train:[99.43] Test:[70.94] | Best Test:[75.66] at Epoch:[48] | 0-0.2:[0.00%] 0.2-0.4:[0.00%] 0.4-0.6:[0.00%] 0.6-0.8:[0.00%] 0.8-1.0:[100.00%]
(Train IMP:[1] fold:[0] spa:[0.00%] spw:[0.00%]) Epoch:[92/100] Loss:[0.0075] Train:[99.81] Test:[71.13] | Best Test:[75.66] at Epoch:[48] | 0-0.2:[0.00%] 0.2-0.4:[0.00%] 0.4-0.6:[0.00%] 0.6-0.8:[0.00%] 0.8-1.0:[100.00%]
(Train IMP:[1] fold:[0] spa:[0.00%] spw:[0.00%]) Epoch:[93/100] Loss:[0.0045] Train:[100.00] Test:[73.58] | Best Test:[75.66] at Epoch:[48] | 0-0.2:[0.00%] 0.2-0.4:[0.00%] 0.4-0.6:[0.00%] 0.6-0.8:[0.00%] 0.8-1.0:[100.00%]
(Train IMP:[1] fold:[0] spa:[0.00%] spw:[0.00%]) Epoch:[94/100] Loss:[0.0198] Train:[99.43] Test:[66.04] | Best Test:[75.66] at Epoch:[48] | 0-0.2:[0.00%] 0.2-0.4:[0.00%] 0.4-0.6:[0.00%] 0.6-0.8:[0.00%] 0.8-1.0:[100.00%]
(Train IMP:[1] fold:[0] spa:[0.00%] spw:[0.00%]) Epoch:[95/100] Loss:[0.0172] Train:[99.25] Test:[67.92] | Best Test:[75.66] at Epoch:[48] | 0-0.2:[0.00%] 0.2-0.4:[0.00%] 0.4-0.6:[0.00%] 0.6-0.8:[0.00%] 0.8-1.0:[100.00%]
(Train IMP:[1] fold:[0] spa:[0.00%] spw:[0.00%]) Epoch:[96/100] Loss:[0.0688] Train:[97.92] Test:[61.89] | Best Test:[75.66] at Epoch:[48] | 0-0.2:[0.00%] 0.2-0.4:[0.00%] 0.4-0.6:[0.00%] 0.6-0.8:[0.00%] 0.8-1.0:[100.00%]
(Train IMP:[1] fold:[0] spa:[0.00%] spw:[0.00%]) Epoch:[97/100] Loss:[0.0567] Train:[98.11] Test:[73.21] | Best Test:[75.66] at Epoch:[48] | 0-0.2:[0.00%] 0.2-0.4:[0.00%] 0.4-0.6:[0.00%] 0.6-0.8:[0.00%] 0.8-1.0:[100.00%]
(Train IMP:[1] fold:[0] spa:[0.00%] spw:[0.00%]) Epoch:[98/100] Loss:[0.0503] Train:[97.92] Test:[71.51] | Best Test:[75.66] at Epoch:[48] | 0-0.2:[0.00%] 0.2-0.4:[0.00%] 0.4-0.6:[0.00%] 0.6-0.8:[0.00%] 0.8-1.0:[100.00%]
(Train IMP:[1] fold:[0] spa:[0.00%] spw:[0.00%]) Epoch:[99/100] Loss:[0.0169] Train:[99.06] Test:[72.64] | Best Test:[75.66] at Epoch:[48] | 0-0.2:[0.00%] 0.2-0.4:[0.00%] 0.4-0.6:[0.00%] 0.6-0.8:[0.00%] 0.8-1.0:[100.00%]
(Train IMP:[1] fold:[0] spa:[0.00%] spw:[0.00%]) Epoch:[100/100] Loss:[0.0216] Train:[99.06] Test:[74.15] | Best Test:[75.66] at Epoch:[48] | 0-0.2:[0.00%] 0.2-0.4:[0.00%] 0.4-0.6:[0.00%] 0.6-0.8:[0.00%] 0.8-1.0:[100.00%]
INFO: Weight Sparsity [0.0000%] 
(Train IMP:[1] fold:[1] spa:[0.00%] spw:[0.00%]) Epoch:[1/100] Loss:[0.5796] Train:[70.19] Test:[43.77] | Best Test:[43.77] at Epoch:[1] | 0-0.2:[11.52%] 0.2-0.4:[10.26%] 0.4-0.6:[23.97%] 0.6-0.8:[24.03%] 0.8-1.0:[30.22%]
(Train IMP:[1] fold:[1] spa:[0.00%] spw:[0.00%]) Epoch:[2/100] Loss:[0.4963] Train:[77.92] Test:[45.47] | Best Test:[45.47] at Epoch:[2] | 0-0.2:[26.88%] 0.2-0.4:[4.94%] 0.4-0.6:[4.77%] 0.6-0.8:[6.55%] 0.8-1.0:[56.87%]
(Train IMP:[1] fold:[1] spa:[0.00%] spw:[0.00%]) Epoch:[3/100] Loss:[0.4544] Train:[79.06] Test:[76.60] | Best Test:[76.60] at Epoch:[3] | 0-0.2:[23.64%] 0.2-0.4:[3.54%] 0.4-0.6:[3.38%] 0.6-0.8:[4.71%] 0.8-1.0:[64.73%]
(Train IMP:[1] fold:[1] spa:[0.00%] spw:[0.00%]) Epoch:[4/100] Loss:[0.4409] Train:[80.38] Test:[46.98] | Best Test:[76.60] at Epoch:[3] | 0-0.2:[16.70%] 0.2-0.4:[2.99%] 0.4-0.6:[3.12%] 0.6-0.8:[4.97%] 0.8-1.0:[72.21%]
(Train IMP:[1] fold:[1] spa:[0.00%] spw:[0.00%]) Epoch:[5/100] Loss:[0.4239] Train:[80.75] Test:[76.98] | Best Test:[76.98] at Epoch:[5] | 0-0.2:[24.83%] 0.2-0.4:[2.46%] 0.4-0.6:[2.29%] 0.6-0.8:[3.08%] 0.8-1.0:[67.33%]
(Train IMP:[1] fold:[1] spa:[0.00%] spw:[0.00%]) Epoch:[6/100] Loss:[0.3844] Train:[83.40] Test:[64.53] | Best Test:[76.98] at Epoch:[5] | 0-0.2:[25.37%] 0.2-0.4:[2.11%] 0.4-0.6:[1.92%] 0.6-0.8:[2.55%] 0.8-1.0:[68.05%]
(Train IMP:[1] fold:[1] spa:[0.00%] spw:[0.00%]) Epoch:[7/100] Loss:[0.3879] Train:[82.08] Test:[44.53] | Best Test:[76.98] at Epoch:[5] | 0-0.2:[30.31%] 0.2-0.4:[1.60%] 0.4-0.6:[1.40%] 0.6-0.8:[1.78%] 0.8-1.0:[64.91%]
(Train IMP:[1] fold:[1] spa:[0.00%] spw:[0.00%]) Epoch:[8/100] Loss:[0.3617] Train:[81.70] Test:[69.62] | Best Test:[76.98] at Epoch:[5] | 0-0.2:[33.77%] 0.2-0.4:[1.40%] 0.4-0.6:[1.17%] 0.6-0.8:[1.46%] 0.8-1.0:[62.20%]
(Train IMP:[1] fold:[1] spa:[0.00%] spw:[0.00%]) Epoch:[9/100] Loss:[0.3351] Train:[85.85] Test:[76.23] | Best Test:[76.98] at Epoch:[5] | 0-0.2:[29.05%] 0.2-0.4:[1.15%] 0.4-0.6:[1.00%] 0.6-0.8:[1.26%] 0.8-1.0:[67.54%]
(Train IMP:[1] fold:[1] spa:[0.00%] spw:[0.00%]) Epoch:[10/100] Loss:[0.3105] Train:[87.36] Test:[74.72] | Best Test:[76.98] at Epoch:[5] | 0-0.2:[24.81%] 0.2-0.4:[0.96%] 0.4-0.6:[0.84%] 0.6-0.8:[1.11%] 0.8-1.0:[72.29%]
(Train IMP:[1] fold:[1] spa:[0.00%] spw:[0.00%]) Epoch:[11/100] Loss:[0.2985] Train:[86.79] Test:[77.74] | Best Test:[77.74] at Epoch:[11] | 0-0.2:[23.56%] 0.2-0.4:[0.85%] 0.4-0.6:[0.73%] 0.6-0.8:[0.91%] 0.8-1.0:[73.95%]
(Train IMP:[1] fold:[1] spa:[0.00%] spw:[0.00%]) Epoch:[12/100] Loss:[0.2644] Train:[89.62] Test:[54.34] | Best Test:[77.74] at Epoch:[11] | 0-0.2:[20.50%] 0.2-0.4:[0.69%] 0.4-0.6:[0.61%] 0.6-0.8:[0.74%] 0.8-1.0:[77.46%]
(Train IMP:[1] fold:[1] spa:[0.00%] spw:[0.00%]) Epoch:[13/100] Loss:[0.2677] Train:[89.43] Test:[75.85] | Best Test:[77.74] at Epoch:[11] | 0-0.2:[15.19%] 0.2-0.4:[0.46%] 0.4-0.6:[0.38%] 0.6-0.8:[0.51%] 0.8-1.0:[83.46%]
(Train IMP:[1] fold:[1] spa:[0.00%] spw:[0.00%]) Epoch:[14/100] Loss:[0.2435] Train:[91.32] Test:[57.55] | Best Test:[77.74] at Epoch:[11] | 0-0.2:[13.68%] 0.2-0.4:[0.42%] 0.4-0.6:[0.36%] 0.6-0.8:[0.45%] 0.8-1.0:[85.09%]
(Train IMP:[1] fold:[1] spa:[0.00%] spw:[0.00%]) Epoch:[15/100] Loss:[0.2239] Train:[89.43] Test:[62.45] | Best Test:[77.74] at Epoch:[11] | 0-0.2:[12.72%] 0.2-0.4:[0.37%] 0.4-0.6:[0.34%] 0.6-0.8:[0.45%] 0.8-1.0:[86.12%]
(Train IMP:[1] fold:[1] spa:[0.00%] spw:[0.00%]) Epoch:[16/100] Loss:[0.2148] Train:[90.19] Test:[66.23] | Best Test:[77.74] at Epoch:[11] | 0-0.2:[9.80%] 0.2-0.4:[0.31%] 0.4-0.6:[0.26%] 0.6-0.8:[0.35%] 0.8-1.0:[89.27%]
(Train IMP:[1] fold:[1] spa:[0.00%] spw:[0.00%]) Epoch:[17/100] Loss:[0.2161] Train:[91.51] Test:[50.38] | Best Test:[77.74] at Epoch:[11] | 0-0.2:[10.48%] 0.2-0.4:[0.32%] 0.4-0.6:[0.27%] 0.6-0.8:[0.34%] 0.8-1.0:[88.59%]
(Train IMP:[1] fold:[1] spa:[0.00%] spw:[0.00%]) Epoch:[18/100] Loss:[0.1397] Train:[94.91] Test:[75.28] | Best Test:[77.74] at Epoch:[11] | 0-0.2:[7.93%] 0.2-0.4:[0.26%] 0.4-0.6:[0.23%] 0.6-0.8:[0.29%] 0.8-1.0:[91.29%]
(Train IMP:[1] fold:[1] spa:[0.00%] spw:[0.00%]) Epoch:[19/100] Loss:[0.1583] Train:[94.72] Test:[64.91] | Best Test:[77.74] at Epoch:[11] | 0-0.2:[6.75%] 0.2-0.4:[0.70%] 0.4-0.6:[0.70%] 0.6-0.8:[1.09%] 0.8-1.0:[90.76%]
(Train IMP:[1] fold:[1] spa:[0.00%] spw:[0.00%]) Epoch:[20/100] Loss:[0.1799] Train:[93.21] Test:[66.98] | Best Test:[77.74] at Epoch:[11] | 0-0.2:[8.29%] 0.2-0.4:[0.19%] 0.4-0.6:[0.16%] 0.6-0.8:[0.21%] 0.8-1.0:[91.16%]
(Train IMP:[1] fold:[1] spa:[0.00%] spw:[0.00%]) Epoch:[21/100] Loss:[0.1630] Train:[93.96] Test:[64.34] | Best Test:[77.74] at Epoch:[11] | 0-0.2:[10.53%] 0.2-0.4:[0.23%] 0.4-0.6:[0.20%] 0.6-0.8:[0.26%] 0.8-1.0:[88.78%]
(Train IMP:[1] fold:[1] spa:[0.00%] spw:[0.00%]) Epoch:[22/100] Loss:[0.1152] Train:[95.47] Test:[76.04] | Best Test:[77.74] at Epoch:[11] | 0-0.2:[8.70%] 0.2-0.4:[0.18%] 0.4-0.6:[0.15%] 0.6-0.8:[0.20%] 0.8-1.0:[90.77%]
(Train IMP:[1] fold:[1] spa:[0.00%] spw:[0.00%]) Epoch:[23/100] Loss:[0.0981] Train:[96.23] Test:[68.68] | Best Test:[77.74] at Epoch:[11] | 0-0.2:[6.63%] 0.2-0.4:[0.14%] 0.4-0.6:[0.12%] 0.6-0.8:[0.15%] 0.8-1.0:[92.95%]
(Train IMP:[1] fold:[1] spa:[0.00%] spw:[0.00%]) Epoch:[24/100] Loss:[0.0701] Train:[97.92] Test:[71.32] | Best Test:[77.74] at Epoch:[11] | 0-0.2:[6.70%] 0.2-0.4:[0.15%] 0.4-0.6:[0.12%] 0.6-0.8:[0.15%] 0.8-1.0:[92.87%]
(Train IMP:[1] fold:[1] spa:[0.00%] spw:[0.00%]) Epoch:[25/100] Loss:[0.1077] Train:[95.66] Test:[73.96] | Best Test:[77.74] at Epoch:[11] | 0-0.2:[6.61%] 0.2-0.4:[0.18%] 0.4-0.6:[0.17%] 0.6-0.8:[0.22%] 0.8-1.0:[92.82%]
(Train IMP:[1] fold:[1] spa:[0.00%] spw:[0.00%]) Epoch:[26/100] Loss:[0.0916] Train:[96.60] Test:[66.60] | Best Test:[77.74] at Epoch:[11] | 0-0.2:[6.72%] 0.2-0.4:[0.08%] 0.4-0.6:[0.07%] 0.6-0.8:[0.09%] 0.8-1.0:[93.04%]
(Train IMP:[1] fold:[1] spa:[0.00%] spw:[0.00%]) Epoch:[27/100] Loss:[0.0744] Train:[97.17] Test:[72.83] | Best Test:[77.74] at Epoch:[11] | 0-0.2:[6.95%] 0.2-0.4:[0.07%] 0.4-0.6:[0.06%] 0.6-0.8:[0.08%] 0.8-1.0:[92.83%]
(Train IMP:[1] fold:[1] spa:[0.00%] spw:[0.00%]) Epoch:[28/100] Loss:[0.1063] Train:[95.47] Test:[69.62] | Best Test:[77.74] at Epoch:[11] | 0-0.2:[9.91%] 0.2-0.4:[0.12%] 0.4-0.6:[0.09%] 0.6-0.8:[0.12%] 0.8-1.0:[89.77%]
(Train IMP:[1] fold:[1] spa:[0.00%] spw:[0.00%]) Epoch:[29/100] Loss:[0.1383] Train:[96.04] Test:[63.02] | Best Test:[77.74] at Epoch:[11] | 0-0.2:[5.62%] 0.2-0.4:[0.05%] 0.4-0.6:[0.04%] 0.6-0.8:[0.06%] 0.8-1.0:[94.23%]
(Train IMP:[1] fold:[1] spa:[0.00%] spw:[0.00%]) Epoch:[30/100] Loss:[0.0975] Train:[96.04] Test:[58.68] | Best Test:[77.74] at Epoch:[11] | 0-0.2:[4.66%] 0.2-0.4:[0.04%] 0.4-0.6:[0.04%] 0.6-0.8:[0.04%] 0.8-1.0:[95.23%]
(Train IMP:[1] fold:[1] spa:[0.00%] spw:[0.00%]) Epoch:[31/100] Loss:[0.1288] Train:[96.42] Test:[66.79] | Best Test:[77.74] at Epoch:[11] | 0-0.2:[4.79%] 0.2-0.4:[0.05%] 0.4-0.6:[0.04%] 0.6-0.8:[0.05%] 0.8-1.0:[95.08%]
(Train IMP:[1] fold:[1] spa:[0.00%] spw:[0.00%]) Epoch:[32/100] Loss:[0.1013] Train:[95.66] Test:[70.19] | Best Test:[77.74] at Epoch:[11] | 0-0.2:[4.09%] 0.2-0.4:[0.04%] 0.4-0.6:[0.03%] 0.6-0.8:[0.04%] 0.8-1.0:[95.80%]
(Train IMP:[1] fold:[1] spa:[0.00%] spw:[0.00%]) Epoch:[33/100] Loss:[0.1004] Train:[95.47] Test:[73.21] | Best Test:[77.74] at Epoch:[11] | 0-0.2:[4.59%] 0.2-0.4:[0.04%] 0.4-0.6:[0.03%] 0.6-0.8:[0.04%] 0.8-1.0:[95.31%]
(Train IMP:[1] fold:[1] spa:[0.00%] spw:[0.00%]) Epoch:[34/100] Loss:[0.0988] Train:[96.60] Test:[71.89] | Best Test:[77.74] at Epoch:[11] | 0-0.2:[5.76%] 0.2-0.4:[0.04%] 0.4-0.6:[0.04%] 0.6-0.8:[0.05%] 0.8-1.0:[94.11%]
(Train IMP:[1] fold:[1] spa:[0.00%] spw:[0.00%]) Epoch:[35/100] Loss:[0.1115] Train:[95.66] Test:[66.60] | Best Test:[77.74] at Epoch:[11] | 0-0.2:[5.34%] 0.2-0.4:[0.05%] 0.4-0.6:[0.04%] 0.6-0.8:[0.05%] 0.8-1.0:[94.53%]
(Train IMP:[1] fold:[1] spa:[0.00%] spw:[0.00%]) Epoch:[36/100] Loss:[0.0556] Train:[98.49] Test:[61.51] | Best Test:[77.74] at Epoch:[11] | 0-0.2:[4.48%] 0.2-0.4:[0.04%] 0.4-0.6:[0.04%] 0.6-0.8:[0.04%] 0.8-1.0:[95.40%]
(Train IMP:[1] fold:[1] spa:[0.00%] spw:[0.00%]) Epoch:[37/100] Loss:[0.1075] Train:[96.23] Test:[63.21] | Best Test:[77.74] at Epoch:[11] | 0-0.2:[5.58%] 0.2-0.4:[0.05%] 0.4-0.6:[0.04%] 0.6-0.8:[0.06%] 0.8-1.0:[94.27%]
(Train IMP:[1] fold:[1] spa:[0.00%] spw:[0.00%]) Epoch:[38/100] Loss:[0.0601] Train:[98.30] Test:[72.64] | Best Test:[77.74] at Epoch:[11] | 0-0.2:[4.64%] 0.2-0.4:[0.04%] 0.4-0.6:[0.03%] 0.6-0.8:[0.04%] 0.8-1.0:[95.25%]
(Train IMP:[1] fold:[1] spa:[0.00%] spw:[0.00%]) Epoch:[39/100] Loss:[0.0479] Train:[97.74] Test:[73.40] | Best Test:[77.74] at Epoch:[11] | 0-0.2:[4.50%] 0.2-0.4:[0.03%] 0.4-0.6:[0.03%] 0.6-0.8:[0.04%] 0.8-1.0:[95.39%]
(Train IMP:[1] fold:[1] spa:[0.00%] spw:[0.00%]) Epoch:[40/100] Loss:[0.0683] Train:[97.36] Test:[61.89] | Best Test:[77.74] at Epoch:[11] | 0-0.2:[3.29%] 0.2-0.4:[0.03%] 0.4-0.6:[0.02%] 0.6-0.8:[0.03%] 0.8-1.0:[96.64%]
(Train IMP:[1] fold:[1] spa:[0.00%] spw:[0.00%]) Epoch:[41/100] Loss:[0.0394] Train:[99.25] Test:[51.70] | Best Test:[77.74] at Epoch:[11] | 0-0.2:[3.19%] 0.2-0.4:[0.02%] 0.4-0.6:[0.02%] 0.6-0.8:[0.02%] 0.8-1.0:[96.75%]
(Train IMP:[1] fold:[1] spa:[0.00%] spw:[0.00%]) Epoch:[42/100] Loss:[0.0300] Train:[98.87] Test:[70.19] | Best Test:[77.74] at Epoch:[11] | 0-0.2:[2.80%] 0.2-0.4:[0.02%] 0.4-0.6:[0.02%] 0.6-0.8:[0.02%] 0.8-1.0:[97.14%]
(Train IMP:[1] fold:[1] spa:[0.00%] spw:[0.00%]) Epoch:[43/100] Loss:[0.0224] Train:[99.06] Test:[70.00] | Best Test:[77.74] at Epoch:[11] | 0-0.2:[2.49%] 0.2-0.4:[0.02%] 0.4-0.6:[0.01%] 0.6-0.8:[0.02%] 0.8-1.0:[97.46%]
(Train IMP:[1] fold:[1] spa:[0.00%] spw:[0.00%]) Epoch:[44/100] Loss:[0.0525] Train:[98.49] Test:[72.64] | Best Test:[77.74] at Epoch:[11] | 0-0.2:[2.25%] 0.2-0.4:[0.01%] 0.4-0.6:[0.01%] 0.6-0.8:[0.02%] 0.8-1.0:[97.71%]
(Train IMP:[1] fold:[1] spa:[0.00%] spw:[0.00%]) Epoch:[45/100] Loss:[0.0378] Train:[98.87] Test:[70.94] | Best Test:[77.74] at Epoch:[11] | 0-0.2:[2.07%] 0.2-0.4:[0.01%] 0.4-0.6:[0.01%] 0.6-0.8:[0.01%] 0.8-1.0:[97.89%]
(Train IMP:[1] fold:[1] spa:[0.00%] spw:[0.00%]) Epoch:[46/100] Loss:[0.0407] Train:[98.49] Test:[71.13] | Best Test:[77.74] at Epoch:[11] | 0-0.2:[1.95%] 0.2-0.4:[0.01%] 0.4-0.6:[0.01%] 0.6-0.8:[0.01%] 0.8-1.0:[98.01%]
(Train IMP:[1] fold:[1] spa:[0.00%] spw:[0.00%]) Epoch:[47/100] Loss:[0.0415] Train:[98.30] Test:[69.81] | Best Test:[77.74] at Epoch:[11] | 0-0.2:[2.03%] 0.2-0.4:[0.01%] 0.4-0.6:[0.01%] 0.6-0.8:[0.01%] 0.8-1.0:[97.94%]
(Train IMP:[1] fold:[1] spa:[0.00%] spw:[0.00%]) Epoch:[48/100] Loss:[0.0539] Train:[97.92] Test:[50.19] | Best Test:[77.74] at Epoch:[11] | 0-0.2:[2.40%] 0.2-0.4:[0.01%] 0.4-0.6:[0.01%] 0.6-0.8:[0.02%] 0.8-1.0:[97.55%]
(Train IMP:[1] fold:[1] spa:[0.00%] spw:[0.00%]) Epoch:[49/100] Loss:[0.0661] Train:[97.55] Test:[58.87] | Best Test:[77.74] at Epoch:[11] | 0-0.2:[2.63%] 0.2-0.4:[0.02%] 0.4-0.6:[0.01%] 0.6-0.8:[0.01%] 0.8-1.0:[97.33%]
(Train IMP:[1] fold:[1] spa:[0.00%] spw:[0.00%]) Epoch:[50/100] Loss:[0.0583] Train:[97.36] Test:[72.08] | Best Test:[77.74] at Epoch:[11] | 0-0.2:[2.64%] 0.2-0.4:[0.02%] 0.4-0.6:[0.01%] 0.6-0.8:[0.02%] 0.8-1.0:[97.31%]
(Train IMP:[1] fold:[1] spa:[0.00%] spw:[0.00%]) Epoch:[51/100] Loss:[0.0547] Train:[98.49] Test:[66.60] | Best Test:[77.74] at Epoch:[11] | 0-0.2:[3.28%] 0.2-0.4:[0.02%] 0.4-0.6:[0.02%] 0.6-0.8:[0.02%] 0.8-1.0:[96.65%]
(Train IMP:[1] fold:[1] spa:[0.00%] spw:[0.00%]) Epoch:[52/100] Loss:[0.0470] Train:[98.30] Test:[65.28] | Best Test:[77.74] at Epoch:[11] | 0-0.2:[3.67%] 0.2-0.4:[0.02%] 0.4-0.6:[0.02%] 0.6-0.8:[0.02%] 0.8-1.0:[96.26%]
(Train IMP:[1] fold:[1] spa:[0.00%] spw:[0.00%]) Epoch:[53/100] Loss:[0.0461] Train:[98.11] Test:[72.08] | Best Test:[77.74] at Epoch:[11] | 0-0.2:[3.63%] 0.2-0.4:[0.03%] 0.4-0.6:[0.02%] 0.6-0.8:[0.02%] 0.8-1.0:[96.29%]
(Train IMP:[1] fold:[1] spa:[0.00%] spw:[0.00%]) Epoch:[54/100] Loss:[0.1147] Train:[96.42] Test:[65.66] | Best Test:[77.74] at Epoch:[11] | 0-0.2:[3.50%] 0.2-0.4:[0.02%] 0.4-0.6:[0.03%] 0.6-0.8:[0.03%] 0.8-1.0:[96.43%]
(Train IMP:[1] fold:[1] spa:[0.00%] spw:[0.00%]) Epoch:[55/100] Loss:[0.0433] Train:[98.49] Test:[67.74] | Best Test:[77.74] at Epoch:[11] | 0-0.2:[2.39%] 0.2-0.4:[0.02%] 0.4-0.6:[0.02%] 0.6-0.8:[0.02%] 0.8-1.0:[97.55%]
(Train IMP:[1] fold:[1] spa:[0.00%] spw:[0.00%]) Epoch:[56/100] Loss:[0.0656] Train:[97.74] Test:[65.66] | Best Test:[77.74] at Epoch:[11] | 0-0.2:[2.00%] 0.2-0.4:[0.02%] 0.4-0.6:[0.01%] 0.6-0.8:[0.02%] 0.8-1.0:[97.95%]
(Train IMP:[1] fold:[1] spa:[0.00%] spw:[0.00%]) Epoch:[57/100] Loss:[0.0300] Train:[99.25] Test:[73.21] | Best Test:[77.74] at Epoch:[11] | 0-0.2:[2.21%] 0.2-0.4:[0.02%] 0.4-0.6:[0.01%] 0.6-0.8:[0.01%] 0.8-1.0:[97.75%]
(Train IMP:[1] fold:[1] spa:[0.00%] spw:[0.00%]) Epoch:[58/100] Loss:[0.0553] Train:[97.92] Test:[71.51] | Best Test:[77.74] at Epoch:[11] | 0-0.2:[2.25%] 0.2-0.4:[0.02%] 0.4-0.6:[0.02%] 0.6-0.8:[0.01%] 0.8-1.0:[97.70%]
(Train IMP:[1] fold:[1] spa:[0.00%] spw:[0.00%]) Epoch:[59/100] Loss:[0.0445] Train:[98.30] Test:[64.72] | Best Test:[77.74] at Epoch:[11] | 0-0.2:[2.31%] 0.2-0.4:[0.02%] 0.4-0.6:[0.01%] 0.6-0.8:[0.02%] 0.8-1.0:[97.64%]
(Train IMP:[1] fold:[1] spa:[0.00%] spw:[0.00%]) Epoch:[60/100] Loss:[0.0602] Train:[98.11] Test:[73.02] | Best Test:[77.74] at Epoch:[11] | 0-0.2:[2.24%] 0.2-0.4:[0.02%] 0.4-0.6:[0.01%] 0.6-0.8:[0.01%] 0.8-1.0:[97.72%]
(Train IMP:[1] fold:[1] spa:[0.00%] spw:[0.00%]) Epoch:[61/100] Loss:[0.0379] Train:[98.68] Test:[69.25] | Best Test:[77.74] at Epoch:[11] | 0-0.2:[2.27%] 0.2-0.4:[0.02%] 0.4-0.6:[0.01%] 0.6-0.8:[0.01%] 0.8-1.0:[97.68%]
(Train IMP:[1] fold:[1] spa:[0.00%] spw:[0.00%]) Epoch:[62/100] Loss:[0.0283] Train:[98.87] Test:[70.19] | Best Test:[77.74] at Epoch:[11] | 0-0.2:[2.12%] 0.2-0.4:[0.01%] 0.4-0.6:[0.01%] 0.6-0.8:[0.02%] 0.8-1.0:[97.84%]
(Train IMP:[1] fold:[1] spa:[0.00%] spw:[0.00%]) Epoch:[63/100] Loss:[0.0073] Train:[100.00] Test:[68.68] | Best Test:[77.74] at Epoch:[11] | 0-0.2:[1.92%] 0.2-0.4:[0.02%] 0.4-0.6:[0.01%] 0.6-0.8:[0.01%] 0.8-1.0:[98.04%]
(Train IMP:[1] fold:[1] spa:[0.00%] spw:[0.00%]) Epoch:[64/100] Loss:[0.0248] Train:[98.87] Test:[70.57] | Best Test:[77.74] at Epoch:[11] | 0-0.2:[1.92%] 0.2-0.4:[0.01%] 0.4-0.6:[0.01%] 0.6-0.8:[0.01%] 0.8-1.0:[98.05%]
(Train IMP:[1] fold:[1] spa:[0.00%] spw:[0.00%]) Epoch:[65/100] Loss:[0.0118] Train:[99.43] Test:[73.58] | Best Test:[77.74] at Epoch:[11] | 0-0.2:[1.93%] 0.2-0.4:[0.01%] 0.4-0.6:[0.01%] 0.6-0.8:[0.02%] 0.8-1.0:[98.03%]
(Train IMP:[1] fold:[1] spa:[0.00%] spw:[0.00%]) Epoch:[66/100] Loss:[0.0187] Train:[99.06] Test:[73.21] | Best Test:[77.74] at Epoch:[11] | 0-0.2:[1.90%] 0.2-0.4:[0.01%] 0.4-0.6:[0.01%] 0.6-0.8:[0.01%] 0.8-1.0:[98.06%]
(Train IMP:[1] fold:[1] spa:[0.00%] spw:[0.00%]) Epoch:[67/100] Loss:[0.0050] Train:[100.00] Test:[72.64] | Best Test:[77.74] at Epoch:[11] | 0-0.2:[1.59%] 0.2-0.4:[0.01%] 0.4-0.6:[0.01%] 0.6-0.8:[0.01%] 0.8-1.0:[98.38%]
(Train IMP:[1] fold:[1] spa:[0.00%] spw:[0.00%]) Epoch:[68/100] Loss:[0.0184] Train:[99.43] Test:[68.68] | Best Test:[77.74] at Epoch:[11] | 0-0.2:[1.49%] 0.2-0.4:[0.01%] 0.4-0.6:[0.01%] 0.6-0.8:[0.01%] 0.8-1.0:[98.48%]
(Train IMP:[1] fold:[1] spa:[0.00%] spw:[0.00%]) Epoch:[69/100] Loss:[0.0347] Train:[98.87] Test:[73.77] | Best Test:[77.74] at Epoch:[11] | 0-0.2:[1.66%] 0.2-0.4:[0.01%] 0.4-0.6:[0.01%] 0.6-0.8:[0.01%] 0.8-1.0:[98.31%]
(Train IMP:[1] fold:[1] spa:[0.00%] spw:[0.00%]) Epoch:[70/100] Loss:[0.0713] Train:[96.60] Test:[69.81] | Best Test:[77.74] at Epoch:[11] | 0-0.2:[2.10%] 0.2-0.4:[0.01%] 0.4-0.6:[0.01%] 0.6-0.8:[0.01%] 0.8-1.0:[97.86%]
(Train IMP:[1] fold:[1] spa:[0.00%] spw:[0.00%]) Epoch:[71/100] Loss:[0.0537] Train:[97.92] Test:[71.70] | Best Test:[77.74] at Epoch:[11] | 0-0.2:[1.76%] 0.2-0.4:[0.01%] 0.4-0.6:[0.01%] 0.6-0.8:[0.01%] 0.8-1.0:[98.21%]
(Train IMP:[1] fold:[1] spa:[0.00%] spw:[0.00%]) Epoch:[72/100] Loss:[0.0347] Train:[98.49] Test:[75.09] | Best Test:[77.74] at Epoch:[11] | 0-0.2:[1.69%] 0.2-0.4:[0.01%] 0.4-0.6:[0.01%] 0.6-0.8:[0.01%] 0.8-1.0:[98.27%]
(Train IMP:[1] fold:[1] spa:[0.00%] spw:[0.00%]) Epoch:[73/100] Loss:[0.0671] Train:[97.55] Test:[71.51] | Best Test:[77.74] at Epoch:[11] | 0-0.2:[1.81%] 0.2-0.4:[0.01%] 0.4-0.6:[0.01%] 0.6-0.8:[0.01%] 0.8-1.0:[98.16%]
(Train IMP:[1] fold:[1] spa:[0.00%] spw:[0.00%]) Epoch:[74/100] Loss:[0.0461] Train:[98.11] Test:[67.17] | Best Test:[77.74] at Epoch:[11] | 0-0.2:[1.75%] 0.2-0.4:[0.01%] 0.4-0.6:[0.01%] 0.6-0.8:[0.02%] 0.8-1.0:[98.21%]
(Train IMP:[1] fold:[1] spa:[0.00%] spw:[0.00%]) Epoch:[75/100] Loss:[0.0529] Train:[98.30] Test:[62.64] | Best Test:[77.74] at Epoch:[11] | 0-0.2:[1.58%] 0.2-0.4:[0.01%] 0.4-0.6:[0.01%] 0.6-0.8:[0.01%] 0.8-1.0:[98.39%]
(Train IMP:[1] fold:[1] spa:[0.00%] spw:[0.00%]) Epoch:[76/100] Loss:[0.0148] Train:[99.62] Test:[70.38] | Best Test:[77.74] at Epoch:[11] | 0-0.2:[1.70%] 0.2-0.4:[0.01%] 0.4-0.6:[0.01%] 0.6-0.8:[0.01%] 0.8-1.0:[98.27%]
(Train IMP:[1] fold:[1] spa:[0.00%] spw:[0.00%]) Epoch:[77/100] Loss:[0.0104] Train:[99.81] Test:[72.45] | Best Test:[77.74] at Epoch:[11] | 0-0.2:[1.81%] 0.2-0.4:[0.01%] 0.4-0.6:[0.01%] 0.6-0.8:[0.01%] 0.8-1.0:[98.16%]
(Train IMP:[1] fold:[1] spa:[0.00%] spw:[0.00%]) Epoch:[78/100] Loss:[0.0038] Train:[100.00] Test:[73.58] | Best Test:[77.74] at Epoch:[11] | 0-0.2:[1.98%] 0.2-0.4:[0.01%] 0.4-0.6:[0.01%] 0.6-0.8:[0.01%] 0.8-1.0:[97.99%]
(Train IMP:[1] fold:[1] spa:[0.00%] spw:[0.00%]) Epoch:[79/100] Loss:[0.0050] Train:[99.81] Test:[73.96] | Best Test:[77.74] at Epoch:[11] | 0-0.2:[2.07%] 0.2-0.4:[0.01%] 0.4-0.6:[0.01%] 0.6-0.8:[0.01%] 0.8-1.0:[97.90%]
(Train IMP:[1] fold:[1] spa:[0.00%] spw:[0.00%]) Epoch:[80/100] Loss:[0.0070] Train:[99.81] Test:[71.89] | Best Test:[77.74] at Epoch:[11] | 0-0.2:[2.11%] 0.2-0.4:[0.01%] 0.4-0.6:[0.01%] 0.6-0.8:[0.01%] 0.8-1.0:[97.86%]
(Train IMP:[1] fold:[1] spa:[0.00%] spw:[0.00%]) Epoch:[81/100] Loss:[0.0433] Train:[98.68] Test:[68.30] | Best Test:[77.74] at Epoch:[11] | 0-0.2:[2.13%] 0.2-0.4:[0.01%] 0.4-0.6:[0.01%] 0.6-0.8:[0.01%] 0.8-1.0:[97.84%]
(Train IMP:[1] fold:[1] spa:[0.00%] spw:[0.00%]) Epoch:[82/100] Loss:[0.0474] Train:[97.74] Test:[71.51] | Best Test:[77.74] at Epoch:[11] | 0-0.2:[2.13%] 0.2-0.4:[0.01%] 0.4-0.6:[0.01%] 0.6-0.8:[0.01%] 0.8-1.0:[97.84%]
(Train IMP:[1] fold:[1] spa:[0.00%] spw:[0.00%]) Epoch:[83/100] Loss:[0.0562] Train:[98.30] Test:[75.85] | Best Test:[77.74] at Epoch:[11] | 0-0.2:[2.12%] 0.2-0.4:[0.01%] 0.4-0.6:[0.01%] 0.6-0.8:[0.01%] 0.8-1.0:[97.85%]
(Train IMP:[1] fold:[1] spa:[0.00%] spw:[0.00%]) Epoch:[84/100] Loss:[0.0988] Train:[96.42] Test:[72.26] | Best Test:[77.74] at Epoch:[11] | 0-0.2:[1.66%] 0.2-0.4:[0.01%] 0.4-0.6:[0.01%] 0.6-0.8:[0.01%] 0.8-1.0:[98.31%]
(Train IMP:[1] fold:[1] spa:[0.00%] spw:[0.00%]) Epoch:[85/100] Loss:[0.0818] Train:[97.36] Test:[72.45] | Best Test:[77.74] at Epoch:[11] | 0-0.2:[1.29%] 0.2-0.4:[0.01%] 0.4-0.6:[0.01%] 0.6-0.8:[0.01%] 0.8-1.0:[98.69%]
(Train IMP:[1] fold:[1] spa:[0.00%] spw:[0.00%]) Epoch:[86/100] Loss:[0.0397] Train:[98.87] Test:[74.91] | Best Test:[77.74] at Epoch:[11] | 0-0.2:[1.36%] 0.2-0.4:[0.01%] 0.4-0.6:[0.01%] 0.6-0.8:[0.01%] 0.8-1.0:[98.62%]
(Train IMP:[1] fold:[1] spa:[0.00%] spw:[0.00%]) Epoch:[87/100] Loss:[0.0349] Train:[98.87] Test:[77.92] | Best Test:[77.92] at Epoch:[87] | 0-0.2:[0.79%] 0.2-0.4:[0.00%] 0.4-0.6:[0.00%] 0.6-0.8:[0.00%] 0.8-1.0:[99.20%]
(Train IMP:[1] fold:[1] spa:[0.00%] spw:[0.00%]) Epoch:[88/100] Loss:[0.0414] Train:[98.87] Test:[72.26] | Best Test:[77.92] at Epoch:[87] | 0-0.2:[0.49%] 0.2-0.4:[0.00%] 0.4-0.6:[0.00%] 0.6-0.8:[0.00%] 0.8-1.0:[99.51%]
(Train IMP:[1] fold:[1] spa:[0.00%] spw:[0.00%]) Epoch:[89/100] Loss:[0.0349] Train:[98.87] Test:[76.04] | Best Test:[77.92] at Epoch:[87] | 0-0.2:[0.59%] 0.2-0.4:[0.00%] 0.4-0.6:[0.00%] 0.6-0.8:[0.00%] 0.8-1.0:[99.41%]
(Train IMP:[1] fold:[1] spa:[0.00%] spw:[0.00%]) Epoch:[90/100] Loss:[0.0099] Train:[99.62] Test:[75.85] | Best Test:[77.92] at Epoch:[87] | 0-0.2:[0.92%] 0.2-0.4:[0.00%] 0.4-0.6:[0.00%] 0.6-0.8:[0.00%] 0.8-1.0:[99.07%]
(Train IMP:[1] fold:[1] spa:[0.00%] spw:[0.00%]) Epoch:[91/100] Loss:[0.0074] Train:[100.00] Test:[74.15] | Best Test:[77.92] at Epoch:[87] | 0-0.2:[0.99%] 0.2-0.4:[0.00%] 0.4-0.6:[0.00%] 0.6-0.8:[0.01%] 0.8-1.0:[99.00%]
(Train IMP:[1] fold:[1] spa:[0.00%] spw:[0.00%]) Epoch:[92/100] Loss:[0.0137] Train:[99.43] Test:[73.40] | Best Test:[77.92] at Epoch:[87] | 0-0.2:[0.86%] 0.2-0.4:[0.00%] 0.4-0.6:[0.00%] 0.6-0.8:[0.01%] 0.8-1.0:[99.13%]
(Train IMP:[1] fold:[1] spa:[0.00%] spw:[0.00%]) Epoch:[93/100] Loss:[0.0291] Train:[99.25] Test:[74.34] | Best Test:[77.92] at Epoch:[87] | 0-0.2:[0.63%] 0.2-0.4:[0.00%] 0.4-0.6:[0.00%] 0.6-0.8:[0.00%] 0.8-1.0:[99.37%]
(Train IMP:[1] fold:[1] spa:[0.00%] spw:[0.00%]) Epoch:[94/100] Loss:[0.0284] Train:[99.62] Test:[67.36] | Best Test:[77.92] at Epoch:[87] | 0-0.2:[0.65%] 0.2-0.4:[0.00%] 0.4-0.6:[0.00%] 0.6-0.8:[0.00%] 0.8-1.0:[99.34%]
(Train IMP:[1] fold:[1] spa:[0.00%] spw:[0.00%]) Epoch:[95/100] Loss:[0.0310] Train:[98.68] Test:[74.34] | Best Test:[77.92] at Epoch:[87] | 0-0.2:[0.93%] 0.2-0.4:[0.00%] 0.4-0.6:[0.00%] 0.6-0.8:[0.00%] 0.8-1.0:[99.07%]
(Train IMP:[1] fold:[1] spa:[0.00%] spw:[0.00%]) Epoch:[96/100] Loss:[0.0219] Train:[99.43] Test:[74.91] | Best Test:[77.92] at Epoch:[87] | 0-0.2:[1.01%] 0.2-0.4:[0.01%] 0.4-0.6:[0.00%] 0.6-0.8:[0.00%] 0.8-1.0:[98.98%]
(Train IMP:[1] fold:[1] spa:[0.00%] spw:[0.00%]) Epoch:[97/100] Loss:[0.0172] Train:[99.43] Test:[72.64] | Best Test:[77.92] at Epoch:[87] | 0-0.2:[0.86%] 0.2-0.4:[0.00%] 0.4-0.6:[0.00%] 0.6-0.8:[0.00%] 0.8-1.0:[99.13%]
(Train IMP:[1] fold:[1] spa:[0.00%] spw:[0.00%]) Epoch:[98/100] Loss:[0.0356] Train:[99.06] Test:[73.77] | Best Test:[77.92] at Epoch:[87] | 0-0.2:[0.90%] 0.2-0.4:[0.00%] 0.4-0.6:[0.00%] 0.6-0.8:[0.00%] 0.8-1.0:[99.09%]
(Train IMP:[1] fold:[1] spa:[0.00%] spw:[0.00%]) Epoch:[99/100] Loss:[0.0124] Train:[99.43] Test:[76.23] | Best Test:[77.92] at Epoch:[87] | 0-0.2:[0.88%] 0.2-0.4:[0.00%] 0.4-0.6:[0.00%] 0.6-0.8:[0.00%] 0.8-1.0:[99.11%]
(Train IMP:[1] fold:[1] spa:[0.00%] spw:[0.00%]) Epoch:[100/100] Loss:[0.0351] Train:[98.87] Test:[70.19] | Best Test:[77.92] at Epoch:[87] | 0-0.2:[1.03%] 0.2-0.4:[0.00%] 0.4-0.6:[0.00%] 0.6-0.8:[0.00%] 0.8-1.0:[98.96%]
save in impckpt/DD-lr-0.01-dim-64/imp-train1.pt
/home/zhiyu/anaconda3/envs/gnn-infer/lib/python3.10/site-packages/torch_geometric/data/in_memory_dataset.py:157: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. The data of the dataset is already cached, so any modifications to `data` will not be reflected when accessing its elements. Clearing the cache now by removing all elements in `dataset._data_list`. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
/home/zhiyu/anaconda3/envs/gnn-infer/lib/python3.10/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead
  warnings.warn(out)
INFO: Weight Sparsity [0.0000%] 
(Test IMP:[1] fold:[0] spa:[4.96%] spw:[0.00%]) Epoch:[1/100] Loss:[0.5553] Train:[72.64] Test:[47.55] | Best Test:[47.55] at Epoch:[1]
(Test IMP:[1] fold:[0] spa:[4.96%] spw:[0.00%]) Epoch:[2/100] Loss:[0.4923] Train:[76.42] Test:[63.02] | Best Test:[63.02] at Epoch:[2]
(Test IMP:[1] fold:[0] spa:[4.96%] spw:[0.00%]) Epoch:[3/100] Loss:[0.4261] Train:[80.00] Test:[76.04] | Best Test:[76.04] at Epoch:[3]
(Test IMP:[1] fold:[0] spa:[4.96%] spw:[0.00%]) Epoch:[4/100] Loss:[0.3743] Train:[82.83] Test:[57.17] | Best Test:[76.04] at Epoch:[3]
(Test IMP:[1] fold:[0] spa:[4.96%] spw:[0.00%]) Epoch:[5/100] Loss:[0.3731] Train:[81.13] Test:[69.43] | Best Test:[76.04] at Epoch:[3]
(Test IMP:[1] fold:[0] spa:[4.96%] spw:[0.00%]) Epoch:[6/100] Loss:[0.3105] Train:[87.17] Test:[74.34] | Best Test:[76.04] at Epoch:[3]
(Test IMP:[1] fold:[0] spa:[4.96%] spw:[0.00%]) Epoch:[7/100] Loss:[0.2536] Train:[91.13] Test:[59.06] | Best Test:[76.04] at Epoch:[3]
(Test IMP:[1] fold:[0] spa:[4.96%] spw:[0.00%]) Epoch:[8/100] Loss:[0.2036] Train:[91.70] Test:[70.57] | Best Test:[76.04] at Epoch:[3]
(Test IMP:[1] fold:[0] spa:[4.96%] spw:[0.00%]) Epoch:[9/100] Loss:[0.2676] Train:[87.92] Test:[64.53] | Best Test:[76.04] at Epoch:[3]
(Test IMP:[1] fold:[0] spa:[4.96%] spw:[0.00%]) Epoch:[10/100] Loss:[0.2262] Train:[90.94] Test:[70.00] | Best Test:[76.04] at Epoch:[3]
(Test IMP:[1] fold:[0] spa:[4.96%] spw:[0.00%]) Epoch:[11/100] Loss:[0.1631] Train:[93.58] Test:[73.77] | Best Test:[76.04] at Epoch:[3]
(Test IMP:[1] fold:[0] spa:[4.96%] spw:[0.00%]) Epoch:[12/100] Loss:[0.1891] Train:[92.83] Test:[46.04] | Best Test:[76.04] at Epoch:[3]
(Test IMP:[1] fold:[0] spa:[4.96%] spw:[0.00%]) Epoch:[13/100] Loss:[0.1367] Train:[95.09] Test:[40.75] | Best Test:[76.04] at Epoch:[3]
(Test IMP:[1] fold:[0] spa:[4.96%] spw:[0.00%]) Epoch:[14/100] Loss:[0.1464] Train:[95.09] Test:[58.30] | Best Test:[76.04] at Epoch:[3]
(Test IMP:[1] fold:[0] spa:[4.96%] spw:[0.00%]) Epoch:[15/100] Loss:[0.1600] Train:[92.08] Test:[73.02] | Best Test:[76.04] at Epoch:[3]
(Test IMP:[1] fold:[0] spa:[4.96%] spw:[0.00%]) Epoch:[16/100] Loss:[0.0750] Train:[98.11] Test:[70.94] | Best Test:[76.04] at Epoch:[3]
(Test IMP:[1] fold:[0] spa:[4.96%] spw:[0.00%]) Epoch:[17/100] Loss:[0.0755] Train:[97.17] Test:[45.28] | Best Test:[76.04] at Epoch:[3]
(Test IMP:[1] fold:[0] spa:[4.96%] spw:[0.00%]) Epoch:[18/100] Loss:[0.0737] Train:[97.17] Test:[69.06] | Best Test:[76.04] at Epoch:[3]
(Test IMP:[1] fold:[0] spa:[4.96%] spw:[0.00%]) Epoch:[19/100] Loss:[0.0897] Train:[96.98] Test:[64.72] | Best Test:[76.04] at Epoch:[3]
(Test IMP:[1] fold:[0] spa:[4.96%] spw:[0.00%]) Epoch:[20/100] Loss:[0.1747] Train:[93.58] Test:[67.92] | Best Test:[76.04] at Epoch:[3]
(Test IMP:[1] fold:[0] spa:[4.96%] spw:[0.00%]) Epoch:[21/100] Loss:[0.1669] Train:[93.21] Test:[70.94] | Best Test:[76.04] at Epoch:[3]
(Test IMP:[1] fold:[0] spa:[4.96%] spw:[0.00%]) Epoch:[22/100] Loss:[0.0929] Train:[96.98] Test:[71.32] | Best Test:[76.04] at Epoch:[3]
(Test IMP:[1] fold:[0] spa:[4.96%] spw:[0.00%]) Epoch:[23/100] Loss:[0.0693] Train:[96.98] Test:[71.51] | Best Test:[76.04] at Epoch:[3]
(Test IMP:[1] fold:[0] spa:[4.96%] spw:[0.00%]) Epoch:[24/100] Loss:[0.0238] Train:[99.43] Test:[68.30] | Best Test:[76.04] at Epoch:[3]
(Test IMP:[1] fold:[0] spa:[4.96%] spw:[0.00%]) Epoch:[25/100] Loss:[0.0560] Train:[98.30] Test:[49.06] | Best Test:[76.04] at Epoch:[3]
(Test IMP:[1] fold:[0] spa:[4.96%] spw:[0.00%]) Epoch:[26/100] Loss:[0.0610] Train:[97.74] Test:[75.09] | Best Test:[76.04] at Epoch:[3]
(Test IMP:[1] fold:[0] spa:[4.96%] spw:[0.00%]) Epoch:[27/100] Loss:[0.0586] Train:[97.74] Test:[68.87] | Best Test:[76.04] at Epoch:[3]
(Test IMP:[1] fold:[0] spa:[4.96%] spw:[0.00%]) Epoch:[28/100] Loss:[0.0867] Train:[96.23] Test:[57.36] | Best Test:[76.04] at Epoch:[3]
(Test IMP:[1] fold:[0] spa:[4.96%] spw:[0.00%]) Epoch:[29/100] Loss:[0.0491] Train:[98.49] Test:[74.53] | Best Test:[76.04] at Epoch:[3]
(Test IMP:[1] fold:[0] spa:[4.96%] spw:[0.00%]) Epoch:[30/100] Loss:[0.0799] Train:[97.17] Test:[62.83] | Best Test:[76.04] at Epoch:[3]
(Test IMP:[1] fold:[0] spa:[4.96%] spw:[0.00%]) Epoch:[31/100] Loss:[0.0436] Train:[98.87] Test:[71.32] | Best Test:[76.04] at Epoch:[3]
(Test IMP:[1] fold:[0] spa:[4.96%] spw:[0.00%]) Epoch:[32/100] Loss:[0.0729] Train:[97.36] Test:[72.45] | Best Test:[76.04] at Epoch:[3]
(Test IMP:[1] fold:[0] spa:[4.96%] spw:[0.00%]) Epoch:[33/100] Loss:[0.0620] Train:[98.30] Test:[69.62] | Best Test:[76.04] at Epoch:[3]
(Test IMP:[1] fold:[0] spa:[4.96%] spw:[0.00%]) Epoch:[34/100] Loss:[0.0296] Train:[99.25] Test:[73.40] | Best Test:[76.04] at Epoch:[3]
(Test IMP:[1] fold:[0] spa:[4.96%] spw:[0.00%]) Epoch:[35/100] Loss:[0.0142] Train:[99.43] Test:[71.89] | Best Test:[76.04] at Epoch:[3]
(Test IMP:[1] fold:[0] spa:[4.96%] spw:[0.00%]) Epoch:[36/100] Loss:[0.0284] Train:[98.68] Test:[72.08] | Best Test:[76.04] at Epoch:[3]
(Test IMP:[1] fold:[0] spa:[4.96%] spw:[0.00%]) Epoch:[37/100] Loss:[0.0660] Train:[97.92] Test:[73.77] | Best Test:[76.04] at Epoch:[3]
(Test IMP:[1] fold:[0] spa:[4.96%] spw:[0.00%]) Epoch:[38/100] Loss:[0.0395] Train:[98.68] Test:[70.57] | Best Test:[76.04] at Epoch:[3]
(Test IMP:[1] fold:[0] spa:[4.96%] spw:[0.00%]) Epoch:[39/100] Loss:[0.0360] Train:[98.68] Test:[71.13] | Best Test:[76.04] at Epoch:[3]
(Test IMP:[1] fold:[0] spa:[4.96%] spw:[0.00%]) Epoch:[40/100] Loss:[0.0595] Train:[97.36] Test:[76.42] | Best Test:[76.42] at Epoch:[40]
(Test IMP:[1] fold:[0] spa:[4.96%] spw:[0.00%]) Epoch:[41/100] Loss:[0.0720] Train:[97.36] Test:[55.47] | Best Test:[76.42] at Epoch:[40]
(Test IMP:[1] fold:[0] spa:[4.96%] spw:[0.00%]) Epoch:[42/100] Loss:[0.1013] Train:[96.98] Test:[72.45] | Best Test:[76.42] at Epoch:[40]
(Test IMP:[1] fold:[0] spa:[4.96%] spw:[0.00%]) Epoch:[43/100] Loss:[0.0707] Train:[97.74] Test:[61.13] | Best Test:[76.42] at Epoch:[40]
(Test IMP:[1] fold:[0] spa:[4.96%] spw:[0.00%]) Epoch:[44/100] Loss:[0.0408] Train:[98.49] Test:[72.64] | Best Test:[76.42] at Epoch:[40]
(Test IMP:[1] fold:[0] spa:[4.96%] spw:[0.00%]) Epoch:[45/100] Loss:[0.0225] Train:[99.43] Test:[72.45] | Best Test:[76.42] at Epoch:[40]
(Test IMP:[1] fold:[0] spa:[4.96%] spw:[0.00%]) Epoch:[46/100] Loss:[0.0327] Train:[99.06] Test:[70.38] | Best Test:[76.42] at Epoch:[40]
(Test IMP:[1] fold:[0] spa:[4.96%] spw:[0.00%]) Epoch:[47/100] Loss:[0.0990] Train:[96.79] Test:[69.25] | Best Test:[76.42] at Epoch:[40]
(Test IMP:[1] fold:[0] spa:[4.96%] spw:[0.00%]) Epoch:[48/100] Loss:[0.0401] Train:[98.30] Test:[72.64] | Best Test:[76.42] at Epoch:[40]
(Test IMP:[1] fold:[0] spa:[4.96%] spw:[0.00%]) Epoch:[49/100] Loss:[0.0424] Train:[98.49] Test:[65.66] | Best Test:[76.42] at Epoch:[40]
(Test IMP:[1] fold:[0] spa:[4.96%] spw:[0.00%]) Epoch:[50/100] Loss:[0.0285] Train:[99.06] Test:[73.02] | Best Test:[76.42] at Epoch:[40]
(Test IMP:[1] fold:[0] spa:[4.96%] spw:[0.00%]) Epoch:[51/100] Loss:[0.0201] Train:[99.06] Test:[69.25] | Best Test:[76.42] at Epoch:[40]
(Test IMP:[1] fold:[0] spa:[4.96%] spw:[0.00%]) Epoch:[52/100] Loss:[0.0136] Train:[99.43] Test:[66.60] | Best Test:[76.42] at Epoch:[40]
(Test IMP:[1] fold:[0] spa:[4.96%] spw:[0.00%]) Epoch:[53/100] Loss:[0.0149] Train:[99.25] Test:[69.62] | Best Test:[76.42] at Epoch:[40]
(Test IMP:[1] fold:[0] spa:[4.96%] spw:[0.00%]) Epoch:[54/100] Loss:[0.0165] Train:[99.25] Test:[70.00] | Best Test:[76.42] at Epoch:[40]
(Test IMP:[1] fold:[0] spa:[4.96%] spw:[0.00%]) Epoch:[55/100] Loss:[0.0498] Train:[99.06] Test:[72.83] | Best Test:[76.42] at Epoch:[40]
(Test IMP:[1] fold:[0] spa:[4.96%] spw:[0.00%]) Epoch:[56/100] Loss:[0.1542] Train:[96.60] Test:[73.40] | Best Test:[76.42] at Epoch:[40]
(Test IMP:[1] fold:[0] spa:[4.96%] spw:[0.00%]) Epoch:[57/100] Loss:[0.1137] Train:[96.60] Test:[68.49] | Best Test:[76.42] at Epoch:[40]
(Test IMP:[1] fold:[0] spa:[4.96%] spw:[0.00%]) Epoch:[58/100] Loss:[0.0577] Train:[97.74] Test:[71.13] | Best Test:[76.42] at Epoch:[40]
(Test IMP:[1] fold:[0] spa:[4.96%] spw:[0.00%]) Epoch:[59/100] Loss:[0.0247] Train:[99.62] Test:[68.49] | Best Test:[76.42] at Epoch:[40]
(Test IMP:[1] fold:[0] spa:[4.96%] spw:[0.00%]) Epoch:[60/100] Loss:[0.0113] Train:[99.62] Test:[72.45] | Best Test:[76.42] at Epoch:[40]
(Test IMP:[1] fold:[0] spa:[4.96%] spw:[0.00%]) Epoch:[61/100] Loss:[0.0088] Train:[99.81] Test:[71.70] | Best Test:[76.42] at Epoch:[40]
(Test IMP:[1] fold:[0] spa:[4.96%] spw:[0.00%]) Epoch:[62/100] Loss:[0.0122] Train:[99.62] Test:[70.75] | Best Test:[76.42] at Epoch:[40]
(Test IMP:[1] fold:[0] spa:[4.96%] spw:[0.00%]) Epoch:[63/100] Loss:[0.0409] Train:[98.68] Test:[70.75] | Best Test:[76.42] at Epoch:[40]
(Test IMP:[1] fold:[0] spa:[4.96%] spw:[0.00%]) Epoch:[64/100] Loss:[0.0165] Train:[99.25] Test:[69.43] | Best Test:[76.42] at Epoch:[40]
(Test IMP:[1] fold:[0] spa:[4.96%] spw:[0.00%]) Epoch:[65/100] Loss:[0.0399] Train:[98.49] Test:[68.87] | Best Test:[76.42] at Epoch:[40]
(Test IMP:[1] fold:[0] spa:[4.96%] spw:[0.00%]) Epoch:[66/100] Loss:[0.0213] Train:[99.06] Test:[74.15] | Best Test:[76.42] at Epoch:[40]
(Test IMP:[1] fold:[0] spa:[4.96%] spw:[0.00%]) Epoch:[67/100] Loss:[0.0107] Train:[99.81] Test:[70.38] | Best Test:[76.42] at Epoch:[40]
(Test IMP:[1] fold:[0] spa:[4.96%] spw:[0.00%]) Epoch:[68/100] Loss:[0.0305] Train:[99.62] Test:[68.11] | Best Test:[76.42] at Epoch:[40]
(Test IMP:[1] fold:[0] spa:[4.96%] spw:[0.00%]) Epoch:[69/100] Loss:[0.0285] Train:[98.49] Test:[73.58] | Best Test:[76.42] at Epoch:[40]
(Test IMP:[1] fold:[0] spa:[4.96%] spw:[0.00%]) Epoch:[70/100] Loss:[0.0370] Train:[98.68] Test:[71.13] | Best Test:[76.42] at Epoch:[40]
(Test IMP:[1] fold:[0] spa:[4.96%] spw:[0.00%]) Epoch:[71/100] Loss:[0.0217] Train:[99.62] Test:[70.75] | Best Test:[76.42] at Epoch:[40]
(Test IMP:[1] fold:[0] spa:[4.96%] spw:[0.00%]) Epoch:[72/100] Loss:[0.0209] Train:[99.81] Test:[76.60] | Best Test:[76.60] at Epoch:[72]
(Test IMP:[1] fold:[0] spa:[4.96%] spw:[0.00%]) Epoch:[73/100] Loss:[0.0044] Train:[100.00] Test:[71.32] | Best Test:[76.60] at Epoch:[72]
(Test IMP:[1] fold:[0] spa:[4.96%] spw:[0.00%]) Epoch:[74/100] Loss:[0.0163] Train:[99.43] Test:[68.68] | Best Test:[76.60] at Epoch:[72]
(Test IMP:[1] fold:[0] spa:[4.96%] spw:[0.00%]) Epoch:[75/100] Loss:[0.0295] Train:[98.87] Test:[57.74] | Best Test:[76.60] at Epoch:[72]
(Test IMP:[1] fold:[0] spa:[4.96%] spw:[0.00%]) Epoch:[76/100] Loss:[0.0225] Train:[99.25] Test:[73.96] | Best Test:[76.60] at Epoch:[72]
(Test IMP:[1] fold:[0] spa:[4.96%] spw:[0.00%]) Epoch:[77/100] Loss:[0.0219] Train:[99.81] Test:[74.34] | Best Test:[76.60] at Epoch:[72]
(Test IMP:[1] fold:[0] spa:[4.96%] spw:[0.00%]) Epoch:[78/100] Loss:[0.0058] Train:[100.00] Test:[72.08] | Best Test:[76.60] at Epoch:[72]
(Test IMP:[1] fold:[0] spa:[4.96%] spw:[0.00%]) Epoch:[79/100] Loss:[0.0026] Train:[100.00] Test:[74.53] | Best Test:[76.60] at Epoch:[72]
(Test IMP:[1] fold:[0] spa:[4.96%] spw:[0.00%]) Epoch:[80/100] Loss:[0.0012] Train:[100.00] Test:[74.53] | Best Test:[76.60] at Epoch:[72]
(Test IMP:[1] fold:[0] spa:[4.96%] spw:[0.00%]) Epoch:[81/100] Loss:[0.0021] Train:[100.00] Test:[72.64] | Best Test:[76.60] at Epoch:[72]
(Test IMP:[1] fold:[0] spa:[4.96%] spw:[0.00%]) Epoch:[82/100] Loss:[0.0384] Train:[98.68] Test:[72.83] | Best Test:[76.60] at Epoch:[72]
(Test IMP:[1] fold:[0] spa:[4.96%] spw:[0.00%]) Epoch:[83/100] Loss:[0.0562] Train:[98.30] Test:[61.13] | Best Test:[76.60] at Epoch:[72]
(Test IMP:[1] fold:[0] spa:[4.96%] spw:[0.00%]) Epoch:[84/100] Loss:[0.0540] Train:[98.11] Test:[66.23] | Best Test:[76.60] at Epoch:[72]
(Test IMP:[1] fold:[0] spa:[4.96%] spw:[0.00%]) Epoch:[85/100] Loss:[0.0300] Train:[98.68] Test:[62.45] | Best Test:[76.60] at Epoch:[72]
(Test IMP:[1] fold:[0] spa:[4.96%] spw:[0.00%]) Epoch:[86/100] Loss:[0.0189] Train:[99.43] Test:[72.45] | Best Test:[76.60] at Epoch:[72]
(Test IMP:[1] fold:[0] spa:[4.96%] spw:[0.00%]) Epoch:[87/100] Loss:[0.0154] Train:[99.62] Test:[73.77] | Best Test:[76.60] at Epoch:[72]
(Test IMP:[1] fold:[0] spa:[4.96%] spw:[0.00%]) Epoch:[88/100] Loss:[0.0187] Train:[99.62] Test:[71.51] | Best Test:[76.60] at Epoch:[72]
(Test IMP:[1] fold:[0] spa:[4.96%] spw:[0.00%]) Epoch:[89/100] Loss:[0.0180] Train:[99.25] Test:[73.96] | Best Test:[76.60] at Epoch:[72]
(Test IMP:[1] fold:[0] spa:[4.96%] spw:[0.00%]) Epoch:[90/100] Loss:[0.0165] Train:[99.43] Test:[70.94] | Best Test:[76.60] at Epoch:[72]
(Test IMP:[1] fold:[0] spa:[4.96%] spw:[0.00%]) Epoch:[91/100] Loss:[0.0207] Train:[99.43] Test:[74.72] | Best Test:[76.60] at Epoch:[72]
(Test IMP:[1] fold:[0] spa:[4.96%] spw:[0.00%]) Epoch:[92/100] Loss:[0.0399] Train:[98.87] Test:[72.26] | Best Test:[76.60] at Epoch:[72]
(Test IMP:[1] fold:[0] spa:[4.96%] spw:[0.00%]) Epoch:[93/100] Loss:[0.0381] Train:[98.68] Test:[70.38] | Best Test:[76.60] at Epoch:[72]
(Test IMP:[1] fold:[0] spa:[4.96%] spw:[0.00%]) Epoch:[94/100] Loss:[0.0255] Train:[98.68] Test:[70.57] | Best Test:[76.60] at Epoch:[72]
(Test IMP:[1] fold:[0] spa:[4.96%] spw:[0.00%]) Epoch:[95/100] Loss:[0.0325] Train:[98.87] Test:[71.32] | Best Test:[76.60] at Epoch:[72]
(Test IMP:[1] fold:[0] spa:[4.96%] spw:[0.00%]) Epoch:[96/100] Loss:[0.0262] Train:[99.06] Test:[75.28] | Best Test:[76.60] at Epoch:[72]
(Test IMP:[1] fold:[0] spa:[4.96%] spw:[0.00%]) Epoch:[97/100] Loss:[0.0268] Train:[98.87] Test:[71.13] | Best Test:[76.60] at Epoch:[72]
(Test IMP:[1] fold:[0] spa:[4.96%] spw:[0.00%]) Epoch:[98/100] Loss:[0.0182] Train:[99.43] Test:[73.40] | Best Test:[76.60] at Epoch:[72]
(Test IMP:[1] fold:[0] spa:[4.96%] spw:[0.00%]) Epoch:[99/100] Loss:[0.0194] Train:[99.25] Test:[71.70] | Best Test:[76.60] at Epoch:[72]
(Test IMP:[1] fold:[0] spa:[4.96%] spw:[0.00%]) Epoch:[100/100] Loss:[0.0111] Train:[99.62] Test:[71.13] | Best Test:[76.60] at Epoch:[72]
[91msyd: IMP:[1] fold:[0] | Dataset:[DD] spa:[4.96%] spw:[0.00%] | Best Test:[76.60] at epoch [72][00m
INFO: Weight Sparsity [0.0000%] 
(Test IMP:[1] fold:[1] spa:[4.96%] spw:[0.00%]) Epoch:[1/100] Loss:[0.5743] Train:[70.00] Test:[44.15] | Best Test:[44.15] at Epoch:[1]
(Test IMP:[1] fold:[1] spa:[4.96%] spw:[0.00%]) Epoch:[2/100] Loss:[0.4930] Train:[77.55] Test:[51.89] | Best Test:[51.89] at Epoch:[2]
(Test IMP:[1] fold:[1] spa:[4.96%] spw:[0.00%]) Epoch:[3/100] Loss:[0.4628] Train:[77.74] Test:[76.42] | Best Test:[76.42] at Epoch:[3]
(Test IMP:[1] fold:[1] spa:[4.96%] spw:[0.00%]) Epoch:[4/100] Loss:[0.3894] Train:[84.15] Test:[66.23] | Best Test:[76.42] at Epoch:[3]
(Test IMP:[1] fold:[1] spa:[4.96%] spw:[0.00%]) Epoch:[5/100] Loss:[0.3789] Train:[83.02] Test:[73.21] | Best Test:[76.42] at Epoch:[3]
(Test IMP:[1] fold:[1] spa:[4.96%] spw:[0.00%]) Epoch:[6/100] Loss:[0.3343] Train:[86.23] Test:[53.77] | Best Test:[76.42] at Epoch:[3]
(Test IMP:[1] fold:[1] spa:[4.96%] spw:[0.00%]) Epoch:[7/100] Loss:[0.3108] Train:[87.74] Test:[70.57] | Best Test:[76.42] at Epoch:[3]
(Test IMP:[1] fold:[1] spa:[4.96%] spw:[0.00%]) Epoch:[8/100] Loss:[0.2647] Train:[87.74] Test:[65.85] | Best Test:[76.42] at Epoch:[3]
(Test IMP:[1] fold:[1] spa:[4.96%] spw:[0.00%]) Epoch:[9/100] Loss:[0.2204] Train:[91.13] Test:[70.38] | Best Test:[76.42] at Epoch:[3]
(Test IMP:[1] fold:[1] spa:[4.96%] spw:[0.00%]) Epoch:[10/100] Loss:[0.1397] Train:[94.34] Test:[70.38] | Best Test:[76.42] at Epoch:[3]
(Test IMP:[1] fold:[1] spa:[4.96%] spw:[0.00%]) Epoch:[11/100] Loss:[0.1975] Train:[92.83] Test:[70.38] | Best Test:[76.42] at Epoch:[3]
(Test IMP:[1] fold:[1] spa:[4.96%] spw:[0.00%]) Epoch:[12/100] Loss:[0.1913] Train:[92.64] Test:[73.58] | Best Test:[76.42] at Epoch:[3]
(Test IMP:[1] fold:[1] spa:[4.96%] spw:[0.00%]) Epoch:[13/100] Loss:[0.1732] Train:[93.77] Test:[67.92] | Best Test:[76.42] at Epoch:[3]
(Test IMP:[1] fold:[1] spa:[4.96%] spw:[0.00%]) Epoch:[14/100] Loss:[0.1574] Train:[93.40] Test:[62.45] | Best Test:[76.42] at Epoch:[3]
(Test IMP:[1] fold:[1] spa:[4.96%] spw:[0.00%]) Epoch:[15/100] Loss:[0.1267] Train:[95.09] Test:[67.92] | Best Test:[76.42] at Epoch:[3]
(Test IMP:[1] fold:[1] spa:[4.96%] spw:[0.00%]) Epoch:[16/100] Loss:[0.1934] Train:[92.83] Test:[51.89] | Best Test:[76.42] at Epoch:[3]
(Test IMP:[1] fold:[1] spa:[4.96%] spw:[0.00%]) Epoch:[17/100] Loss:[0.1070] Train:[95.85] Test:[72.26] | Best Test:[76.42] at Epoch:[3]
(Test IMP:[1] fold:[1] spa:[4.96%] spw:[0.00%]) Epoch:[18/100] Loss:[0.0769] Train:[97.74] Test:[62.45] | Best Test:[76.42] at Epoch:[3]
(Test IMP:[1] fold:[1] spa:[4.96%] spw:[0.00%]) Epoch:[19/100] Loss:[0.0588] Train:[98.30] Test:[65.47] | Best Test:[76.42] at Epoch:[3]
(Test IMP:[1] fold:[1] spa:[4.96%] spw:[0.00%]) Epoch:[20/100] Loss:[0.0954] Train:[96.60] Test:[56.23] | Best Test:[76.42] at Epoch:[3]
(Test IMP:[1] fold:[1] spa:[4.96%] spw:[0.00%]) Epoch:[21/100] Loss:[0.1295] Train:[94.72] Test:[66.04] | Best Test:[76.42] at Epoch:[3]
(Test IMP:[1] fold:[1] spa:[4.96%] spw:[0.00%]) Epoch:[22/100] Loss:[0.1517] Train:[94.34] Test:[64.72] | Best Test:[76.42] at Epoch:[3]
(Test IMP:[1] fold:[1] spa:[4.96%] spw:[0.00%]) Epoch:[23/100] Loss:[0.0717] Train:[97.92] Test:[67.74] | Best Test:[76.42] at Epoch:[3]
(Test IMP:[1] fold:[1] spa:[4.96%] spw:[0.00%]) Epoch:[24/100] Loss:[0.0586] Train:[97.17] Test:[60.57] | Best Test:[76.42] at Epoch:[3]
(Test IMP:[1] fold:[1] spa:[4.96%] spw:[0.00%]) Epoch:[25/100] Loss:[0.0601] Train:[96.98] Test:[73.40] | Best Test:[76.42] at Epoch:[3]
(Test IMP:[1] fold:[1] spa:[4.96%] spw:[0.00%]) Epoch:[26/100] Loss:[0.0860] Train:[97.36] Test:[70.94] | Best Test:[76.42] at Epoch:[3]
(Test IMP:[1] fold:[1] spa:[4.96%] spw:[0.00%]) Epoch:[27/100] Loss:[0.0466] Train:[99.06] Test:[76.42] | Best Test:[76.42] at Epoch:[3]
(Test IMP:[1] fold:[1] spa:[4.96%] spw:[0.00%]) Epoch:[28/100] Loss:[0.0341] Train:[99.06] Test:[52.08] | Best Test:[76.42] at Epoch:[3]
(Test IMP:[1] fold:[1] spa:[4.96%] spw:[0.00%]) Epoch:[29/100] Loss:[0.0430] Train:[98.30] Test:[68.49] | Best Test:[76.42] at Epoch:[3]
(Test IMP:[1] fold:[1] spa:[4.96%] spw:[0.00%]) Epoch:[30/100] Loss:[0.0776] Train:[97.17] Test:[51.13] | Best Test:[76.42] at Epoch:[3]
(Test IMP:[1] fold:[1] spa:[4.96%] spw:[0.00%]) Epoch:[31/100] Loss:[0.1098] Train:[96.04] Test:[58.49] | Best Test:[76.42] at Epoch:[3]
(Test IMP:[1] fold:[1] spa:[4.96%] spw:[0.00%]) Epoch:[32/100] Loss:[0.0816] Train:[96.79] Test:[72.83] | Best Test:[76.42] at Epoch:[3]
(Test IMP:[1] fold:[1] spa:[4.96%] spw:[0.00%]) Epoch:[33/100] Loss:[0.0805] Train:[97.36] Test:[63.77] | Best Test:[76.42] at Epoch:[3]
(Test IMP:[1] fold:[1] spa:[4.96%] spw:[0.00%]) Epoch:[34/100] Loss:[0.0616] Train:[97.74] Test:[71.32] | Best Test:[76.42] at Epoch:[3]
(Test IMP:[1] fold:[1] spa:[4.96%] spw:[0.00%]) Epoch:[35/100] Loss:[0.0791] Train:[97.55] Test:[69.06] | Best Test:[76.42] at Epoch:[3]
(Test IMP:[1] fold:[1] spa:[4.96%] spw:[0.00%]) Epoch:[36/100] Loss:[0.0376] Train:[98.49] Test:[73.96] | Best Test:[76.42] at Epoch:[3]
(Test IMP:[1] fold:[1] spa:[4.96%] spw:[0.00%]) Epoch:[37/100] Loss:[0.0328] Train:[99.25] Test:[69.25] | Best Test:[76.42] at Epoch:[3]
(Test IMP:[1] fold:[1] spa:[4.96%] spw:[0.00%]) Epoch:[38/100] Loss:[0.0793] Train:[96.79] Test:[66.04] | Best Test:[76.42] at Epoch:[3]
(Test IMP:[1] fold:[1] spa:[4.96%] spw:[0.00%]) Epoch:[39/100] Loss:[0.0644] Train:[97.74] Test:[67.17] | Best Test:[76.42] at Epoch:[3]
(Test IMP:[1] fold:[1] spa:[4.96%] spw:[0.00%]) Epoch:[40/100] Loss:[0.0850] Train:[96.98] Test:[71.51] | Best Test:[76.42] at Epoch:[3]
(Test IMP:[1] fold:[1] spa:[4.96%] spw:[0.00%]) Epoch:[41/100] Loss:[0.0777] Train:[97.36] Test:[70.38] | Best Test:[76.42] at Epoch:[3]
(Test IMP:[1] fold:[1] spa:[4.96%] spw:[0.00%]) Epoch:[42/100] Loss:[0.0426] Train:[99.06] Test:[72.45] | Best Test:[76.42] at Epoch:[3]
(Test IMP:[1] fold:[1] spa:[4.96%] spw:[0.00%]) Epoch:[43/100] Loss:[0.0474] Train:[98.30] Test:[66.23] | Best Test:[76.42] at Epoch:[3]
(Test IMP:[1] fold:[1] spa:[4.96%] spw:[0.00%]) Epoch:[44/100] Loss:[0.0197] Train:[99.62] Test:[64.34] | Best Test:[76.42] at Epoch:[3]
(Test IMP:[1] fold:[1] spa:[4.96%] spw:[0.00%]) Epoch:[45/100] Loss:[0.0330] Train:[98.49] Test:[68.87] | Best Test:[76.42] at Epoch:[3]
(Test IMP:[1] fold:[1] spa:[4.96%] spw:[0.00%]) Epoch:[46/100] Loss:[0.0432] Train:[98.87] Test:[56.04] | Best Test:[76.42] at Epoch:[3]
(Test IMP:[1] fold:[1] spa:[4.96%] spw:[0.00%]) Epoch:[47/100] Loss:[0.0142] Train:[99.81] Test:[70.00] | Best Test:[76.42] at Epoch:[3]
(Test IMP:[1] fold:[1] spa:[4.96%] spw:[0.00%]) Epoch:[48/100] Loss:[0.0341] Train:[99.06] Test:[66.79] | Best Test:[76.42] at Epoch:[3]
(Test IMP:[1] fold:[1] spa:[4.96%] spw:[0.00%]) Epoch:[49/100] Loss:[0.0446] Train:[98.49] Test:[68.68] | Best Test:[76.42] at Epoch:[3]
(Test IMP:[1] fold:[1] spa:[4.96%] spw:[0.00%]) Epoch:[50/100] Loss:[0.0821] Train:[96.42] Test:[65.66] | Best Test:[76.42] at Epoch:[3]
(Test IMP:[1] fold:[1] spa:[4.96%] spw:[0.00%]) Epoch:[51/100] Loss:[0.0571] Train:[97.55] Test:[63.96] | Best Test:[76.42] at Epoch:[3]
(Test IMP:[1] fold:[1] spa:[4.96%] spw:[0.00%]) Epoch:[52/100] Loss:[0.0449] Train:[98.30] Test:[72.26] | Best Test:[76.42] at Epoch:[3]
(Test IMP:[1] fold:[1] spa:[4.96%] spw:[0.00%]) Epoch:[53/100] Loss:[0.0425] Train:[98.49] Test:[71.89] | Best Test:[76.42] at Epoch:[3]
(Test IMP:[1] fold:[1] spa:[4.96%] spw:[0.00%]) Epoch:[54/100] Loss:[0.0248] Train:[98.68] Test:[75.28] | Best Test:[76.42] at Epoch:[3]
(Test IMP:[1] fold:[1] spa:[4.96%] spw:[0.00%]) Epoch:[55/100] Loss:[0.0294] Train:[98.87] Test:[74.72] | Best Test:[76.42] at Epoch:[3]
(Test IMP:[1] fold:[1] spa:[4.96%] spw:[0.00%]) Epoch:[56/100] Loss:[0.0359] Train:[98.68] Test:[68.87] | Best Test:[76.42] at Epoch:[3]
(Test IMP:[1] fold:[1] spa:[4.96%] spw:[0.00%]) Epoch:[57/100] Loss:[0.0661] Train:[97.74] Test:[68.30] | Best Test:[76.42] at Epoch:[3]
(Test IMP:[1] fold:[1] spa:[4.96%] spw:[0.00%]) Epoch:[58/100] Loss:[0.0433] Train:[98.30] Test:[67.55] | Best Test:[76.42] at Epoch:[3]
(Test IMP:[1] fold:[1] spa:[4.96%] spw:[0.00%]) Epoch:[59/100] Loss:[0.0211] Train:[99.43] Test:[72.45] | Best Test:[76.42] at Epoch:[3]
(Test IMP:[1] fold:[1] spa:[4.96%] spw:[0.00%]) Epoch:[60/100] Loss:[0.0225] Train:[99.25] Test:[71.70] | Best Test:[76.42] at Epoch:[3]
(Test IMP:[1] fold:[1] spa:[4.96%] spw:[0.00%]) Epoch:[61/100] Loss:[0.0180] Train:[99.43] Test:[65.85] | Best Test:[76.42] at Epoch:[3]
(Test IMP:[1] fold:[1] spa:[4.96%] spw:[0.00%]) Epoch:[62/100] Loss:[0.0307] Train:[98.87] Test:[69.81] | Best Test:[76.42] at Epoch:[3]
(Test IMP:[1] fold:[1] spa:[4.96%] spw:[0.00%]) Epoch:[63/100] Loss:[0.0200] Train:[99.43] Test:[70.57] | Best Test:[76.42] at Epoch:[3]
(Test IMP:[1] fold:[1] spa:[4.96%] spw:[0.00%]) Epoch:[64/100] Loss:[0.0337] Train:[98.30] Test:[62.64] | Best Test:[76.42] at Epoch:[3]
(Test IMP:[1] fold:[1] spa:[4.96%] spw:[0.00%]) Epoch:[65/100] Loss:[0.0607] Train:[97.74] Test:[50.38] | Best Test:[76.42] at Epoch:[3]
(Test IMP:[1] fold:[1] spa:[4.96%] spw:[0.00%]) Epoch:[66/100] Loss:[0.1011] Train:[95.66] Test:[67.36] | Best Test:[76.42] at Epoch:[3]
(Test IMP:[1] fold:[1] spa:[4.96%] spw:[0.00%]) Epoch:[67/100] Loss:[0.0581] Train:[97.74] Test:[73.77] | Best Test:[76.42] at Epoch:[3]
(Test IMP:[1] fold:[1] spa:[4.96%] spw:[0.00%]) Epoch:[68/100] Loss:[0.0147] Train:[99.81] Test:[71.70] | Best Test:[76.42] at Epoch:[3]
(Test IMP:[1] fold:[1] spa:[4.96%] spw:[0.00%]) Epoch:[69/100] Loss:[0.0153] Train:[99.62] Test:[72.45] | Best Test:[76.42] at Epoch:[3]
(Test IMP:[1] fold:[1] spa:[4.96%] spw:[0.00%]) Epoch:[70/100] Loss:[0.0221] Train:[99.43] Test:[70.57] | Best Test:[76.42] at Epoch:[3]
(Test IMP:[1] fold:[1] spa:[4.96%] spw:[0.00%]) Epoch:[71/100] Loss:[0.0145] Train:[99.25] Test:[70.94] | Best Test:[76.42] at Epoch:[3]
(Test IMP:[1] fold:[1] spa:[4.96%] spw:[0.00%]) Epoch:[72/100] Loss:[0.0047] Train:[100.00] Test:[73.21] | Best Test:[76.42] at Epoch:[3]
(Test IMP:[1] fold:[1] spa:[4.96%] spw:[0.00%]) Epoch:[73/100] Loss:[0.0028] Train:[100.00] Test:[72.08] | Best Test:[76.42] at Epoch:[3]
(Test IMP:[1] fold:[1] spa:[4.96%] spw:[0.00%]) Epoch:[74/100] Loss:[0.0073] Train:[99.81] Test:[70.57] | Best Test:[76.42] at Epoch:[3]
(Test IMP:[1] fold:[1] spa:[4.96%] spw:[0.00%]) Epoch:[75/100] Loss:[0.0107] Train:[99.81] Test:[66.23] | Best Test:[76.42] at Epoch:[3]
(Test IMP:[1] fold:[1] spa:[4.96%] spw:[0.00%]) Epoch:[76/100] Loss:[0.0072] Train:[99.62] Test:[65.28] | Best Test:[76.42] at Epoch:[3]
(Test IMP:[1] fold:[1] spa:[4.96%] spw:[0.00%]) Epoch:[77/100] Loss:[0.0196] Train:[99.43] Test:[69.62] | Best Test:[76.42] at Epoch:[3]
(Test IMP:[1] fold:[1] spa:[4.96%] spw:[0.00%]) Epoch:[78/100] Loss:[0.0158] Train:[99.43] Test:[71.89] | Best Test:[76.42] at Epoch:[3]
(Test IMP:[1] fold:[1] spa:[4.96%] spw:[0.00%]) Epoch:[79/100] Loss:[0.0470] Train:[98.68] Test:[72.45] | Best Test:[76.42] at Epoch:[3]
(Test IMP:[1] fold:[1] spa:[4.96%] spw:[0.00%]) Epoch:[80/100] Loss:[0.0922] Train:[96.42] Test:[68.49] | Best Test:[76.42] at Epoch:[3]
(Test IMP:[1] fold:[1] spa:[4.96%] spw:[0.00%]) Epoch:[81/100] Loss:[0.0639] Train:[98.11] Test:[74.53] | Best Test:[76.42] at Epoch:[3]
(Test IMP:[1] fold:[1] spa:[4.96%] spw:[0.00%]) Epoch:[82/100] Loss:[0.0198] Train:[99.25] Test:[73.40] | Best Test:[76.42] at Epoch:[3]
(Test IMP:[1] fold:[1] spa:[4.96%] spw:[0.00%]) Epoch:[83/100] Loss:[0.0235] Train:[99.25] Test:[66.98] | Best Test:[76.42] at Epoch:[3]
(Test IMP:[1] fold:[1] spa:[4.96%] spw:[0.00%]) Epoch:[84/100] Loss:[0.0116] Train:[99.62] Test:[72.08] | Best Test:[76.42] at Epoch:[3]
(Test IMP:[1] fold:[1] spa:[4.96%] spw:[0.00%]) Epoch:[85/100] Loss:[0.0111] Train:[99.62] Test:[68.30] | Best Test:[76.42] at Epoch:[3]
(Test IMP:[1] fold:[1] spa:[4.96%] spw:[0.00%]) Epoch:[86/100] Loss:[0.0036] Train:[100.00] Test:[71.89] | Best Test:[76.42] at Epoch:[3]
(Test IMP:[1] fold:[1] spa:[4.96%] spw:[0.00%]) Epoch:[87/100] Loss:[0.0359] Train:[99.06] Test:[75.28] | Best Test:[76.42] at Epoch:[3]
(Test IMP:[1] fold:[1] spa:[4.96%] spw:[0.00%]) Epoch:[88/100] Loss:[0.0497] Train:[98.30] Test:[68.87] | Best Test:[76.42] at Epoch:[3]
(Test IMP:[1] fold:[1] spa:[4.96%] spw:[0.00%]) Epoch:[89/100] Loss:[0.0227] Train:[99.06] Test:[71.13] | Best Test:[76.42] at Epoch:[3]
(Test IMP:[1] fold:[1] spa:[4.96%] spw:[0.00%]) Epoch:[90/100] Loss:[0.0263] Train:[99.25] Test:[72.08] | Best Test:[76.42] at Epoch:[3]
(Test IMP:[1] fold:[1] spa:[4.96%] spw:[0.00%]) Epoch:[91/100] Loss:[0.0116] Train:[99.81] Test:[71.13] | Best Test:[76.42] at Epoch:[3]
(Test IMP:[1] fold:[1] spa:[4.96%] spw:[0.00%]) Epoch:[92/100] Loss:[0.0108] Train:[99.81] Test:[68.11] | Best Test:[76.42] at Epoch:[3]
(Test IMP:[1] fold:[1] spa:[4.96%] spw:[0.00%]) Epoch:[93/100] Loss:[0.0027] Train:[100.00] Test:[70.19] | Best Test:[76.42] at Epoch:[3]
(Test IMP:[1] fold:[1] spa:[4.96%] spw:[0.00%]) Epoch:[94/100] Loss:[0.0047] Train:[99.81] Test:[71.32] | Best Test:[76.42] at Epoch:[3]
(Test IMP:[1] fold:[1] spa:[4.96%] spw:[0.00%]) Epoch:[95/100] Loss:[0.0126] Train:[99.62] Test:[71.13] | Best Test:[76.42] at Epoch:[3]
(Test IMP:[1] fold:[1] spa:[4.96%] spw:[0.00%]) Epoch:[96/100] Loss:[0.0658] Train:[97.92] Test:[67.17] | Best Test:[76.42] at Epoch:[3]
(Test IMP:[1] fold:[1] spa:[4.96%] spw:[0.00%]) Epoch:[97/100] Loss:[0.0336] Train:[98.68] Test:[70.94] | Best Test:[76.42] at Epoch:[3]
(Test IMP:[1] fold:[1] spa:[4.96%] spw:[0.00%]) Epoch:[98/100] Loss:[0.0418] Train:[99.06] Test:[61.32] | Best Test:[76.42] at Epoch:[3]
(Test IMP:[1] fold:[1] spa:[4.96%] spw:[0.00%]) Epoch:[99/100] Loss:[0.0554] Train:[97.74] Test:[71.51] | Best Test:[76.42] at Epoch:[3]
(Test IMP:[1] fold:[1] spa:[4.96%] spw:[0.00%]) Epoch:[100/100] Loss:[0.0077] Train:[99.81] Test:[70.57] | Best Test:[76.42] at Epoch:[3]
[91msyd: IMP:[1] fold:[1] | Dataset:[DD] spa:[4.96%] spw:[0.00%] | Best Test:[76.42] at epoch [3][00m
[91msydall Final Dataset:[DD] IMP:[1] | spa:[4.96%] spw:[0.00%] | Test Acc:76.23±0.27 | 
sydal: Selected epoch:2 | acc list:[0.7603773474693298, 0.7641509175300598][00m
save in impckpt/DD-lr-0.01-dim-64/imp-eval1.pt
/home/zhiyu/anaconda3/envs/gnn-infer/lib/python3.10/site-packages/torch_geometric/data/in_memory_dataset.py:157: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. The data of the dataset is already cached, so any modifications to `data` will not be reflected when accessing its elements. Clearing the cache now by removing all elements in `dataset._data_list`. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
/home/zhiyu/anaconda3/envs/gnn-infer/lib/python3.10/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead
  warnings.warn(out)
INFO: Weight Sparsity [0.0000%] 
(Train IMP:[2] fold:[0] spa:[4.96%] spw:[0.00%]) Epoch:[1/100] Loss:[0.5504] Train:[72.26] Test:[43.58] | Best Test:[43.58] at Epoch:[1] | 0-0.2:[29.14%] 0.2-0.4:[5.82%] 0.4-0.6:[10.44%] 0.6-0.8:[10.88%] 0.8-1.0:[43.73%]
(Train IMP:[2] fold:[0] spa:[4.96%] spw:[0.00%]) Epoch:[2/100] Loss:[0.5203] Train:[75.47] Test:[53.02] | Best Test:[53.02] at Epoch:[2] | 0-0.2:[44.21%] 0.2-0.4:[1.94%] 0.4-0.6:[1.60%] 0.6-0.8:[1.97%] 0.8-1.0:[50.27%]
(Train IMP:[2] fold:[0] spa:[4.96%] spw:[0.00%]) Epoch:[3/100] Loss:[0.5110] Train:[76.04] Test:[66.04] | Best Test:[66.04] at Epoch:[3] | 0-0.2:[43.81%] 0.2-0.4:[1.22%] 0.4-0.6:[1.04%] 0.6-0.8:[1.21%] 0.8-1.0:[52.72%]
(Train IMP:[2] fold:[0] spa:[4.96%] spw:[0.00%]) Epoch:[4/100] Loss:[0.4741] Train:[77.92] Test:[76.79] | Best Test:[76.79] at Epoch:[4] | 0-0.2:[38.43%] 0.2-0.4:[1.15%] 0.4-0.6:[0.99%] 0.6-0.8:[1.16%] 0.8-1.0:[58.27%]
(Train IMP:[2] fold:[0] spa:[4.96%] spw:[0.00%]) Epoch:[5/100] Loss:[0.4194] Train:[81.89] Test:[77.74] | Best Test:[77.74] at Epoch:[5] | 0-0.2:[36.22%] 0.2-0.4:[1.15%] 0.4-0.6:[0.95%] 0.6-0.8:[1.19%] 0.8-1.0:[60.50%]
(Train IMP:[2] fold:[0] spa:[4.96%] spw:[0.00%]) Epoch:[6/100] Loss:[0.4048] Train:[82.64] Test:[43.58] | Best Test:[77.74] at Epoch:[5] | 0-0.2:[35.29%] 0.2-0.4:[1.06%] 0.4-0.6:[0.91%] 0.6-0.8:[1.13%] 0.8-1.0:[61.61%]
(Train IMP:[2] fold:[0] spa:[4.96%] spw:[0.00%]) Epoch:[7/100] Loss:[0.4231] Train:[81.70] Test:[72.26] | Best Test:[77.74] at Epoch:[5] | 0-0.2:[30.37%] 0.2-0.4:[0.85%] 0.4-0.6:[0.72%] 0.6-0.8:[0.88%] 0.8-1.0:[67.18%]
(Train IMP:[2] fold:[0] spa:[4.96%] spw:[0.00%]) Epoch:[8/100] Loss:[0.3604] Train:[84.53] Test:[69.25] | Best Test:[77.74] at Epoch:[5] | 0-0.2:[32.35%] 0.2-0.4:[0.73%] 0.4-0.6:[0.63%] 0.6-0.8:[0.77%] 0.8-1.0:[65.51%]
(Train IMP:[2] fold:[0] spa:[4.96%] spw:[0.00%]) Epoch:[9/100] Loss:[0.3448] Train:[86.42] Test:[65.66] | Best Test:[77.74] at Epoch:[5] | 0-0.2:[29.65%] 0.2-0.4:[0.74%] 0.4-0.6:[0.62%] 0.6-0.8:[0.76%] 0.8-1.0:[68.22%]
(Train IMP:[2] fold:[0] spa:[4.96%] spw:[0.00%]) Epoch:[10/100] Loss:[0.3502] Train:[84.72] Test:[69.81] | Best Test:[77.74] at Epoch:[5] | 0-0.2:[26.06%] 0.2-0.4:[0.60%] 0.4-0.6:[0.47%] 0.6-0.8:[0.61%] 0.8-1.0:[72.26%]
(Train IMP:[2] fold:[0] spa:[4.96%] spw:[0.00%]) Epoch:[11/100] Loss:[0.3142] Train:[86.60] Test:[65.85] | Best Test:[77.74] at Epoch:[5] | 0-0.2:[23.59%] 0.2-0.4:[0.51%] 0.4-0.6:[0.42%] 0.6-0.8:[0.53%] 0.8-1.0:[74.95%]
(Train IMP:[2] fold:[0] spa:[4.96%] spw:[0.00%]) Epoch:[12/100] Loss:[0.2918] Train:[88.30] Test:[59.81] | Best Test:[77.74] at Epoch:[5] | 0-0.2:[16.26%] 0.2-0.4:[0.37%] 0.4-0.6:[0.30%] 0.6-0.8:[0.38%] 0.8-1.0:[82.70%]
(Train IMP:[2] fold:[0] spa:[4.96%] spw:[0.00%]) Epoch:[13/100] Loss:[0.2540] Train:[88.11] Test:[65.85] | Best Test:[77.74] at Epoch:[5] | 0-0.2:[16.14%] 0.2-0.4:[0.30%] 0.4-0.6:[0.25%] 0.6-0.8:[0.31%] 0.8-1.0:[83.00%]
(Train IMP:[2] fold:[0] spa:[4.96%] spw:[0.00%]) Epoch:[14/100] Loss:[0.2612] Train:[90.19] Test:[45.85] | Best Test:[77.74] at Epoch:[5] | 0-0.2:[13.06%] 0.2-0.4:[0.23%] 0.4-0.6:[0.21%] 0.6-0.8:[0.25%] 0.8-1.0:[86.26%]
(Train IMP:[2] fold:[0] spa:[4.96%] spw:[0.00%]) Epoch:[15/100] Loss:[0.2219] Train:[90.94] Test:[66.60] | Best Test:[77.74] at Epoch:[5] | 0-0.2:[9.94%] 0.2-0.4:[0.16%] 0.4-0.6:[0.14%] 0.6-0.8:[0.19%] 0.8-1.0:[89.57%]
(Train IMP:[2] fold:[0] spa:[4.96%] spw:[0.00%]) Epoch:[16/100] Loss:[0.1685] Train:[93.58] Test:[52.08] | Best Test:[77.74] at Epoch:[5] | 0-0.2:[11.04%] 0.2-0.4:[0.15%] 0.4-0.6:[0.14%] 0.6-0.8:[0.16%] 0.8-1.0:[88.51%]
(Train IMP:[2] fold:[0] spa:[4.96%] spw:[0.00%]) Epoch:[17/100] Loss:[0.2412] Train:[90.57] Test:[74.34] | Best Test:[77.74] at Epoch:[5] | 0-0.2:[12.77%] 0.2-0.4:[0.18%] 0.4-0.6:[0.16%] 0.6-0.8:[0.19%] 0.8-1.0:[86.70%]
(Train IMP:[2] fold:[0] spa:[4.96%] spw:[0.00%]) Epoch:[18/100] Loss:[0.2104] Train:[91.89] Test:[70.00] | Best Test:[77.74] at Epoch:[5] | 0-0.2:[15.37%] 0.2-0.4:[0.17%] 0.4-0.6:[0.14%] 0.6-0.8:[0.17%] 0.8-1.0:[84.15%]
(Train IMP:[2] fold:[0] spa:[4.96%] spw:[0.00%]) Epoch:[19/100] Loss:[0.3345] Train:[85.09] Test:[69.62] | Best Test:[77.74] at Epoch:[5] | 0-0.2:[29.60%] 0.2-0.4:[0.22%] 0.4-0.6:[0.17%] 0.6-0.8:[0.22%] 0.8-1.0:[69.78%]
(Train IMP:[2] fold:[0] spa:[4.96%] spw:[0.00%]) Epoch:[20/100] Loss:[0.4785] Train:[79.25] Test:[55.66] | Best Test:[77.74] at Epoch:[5] | 0-0.2:[58.43%] 0.2-0.4:[0.37%] 0.4-0.6:[0.30%] 0.6-0.8:[0.38%] 0.8-1.0:[40.51%]
(Train IMP:[2] fold:[0] spa:[4.96%] spw:[0.00%]) Epoch:[21/100] Loss:[0.4621] Train:[79.43] Test:[65.47] | Best Test:[77.74] at Epoch:[5] | 0-0.2:[52.35%] 0.2-0.4:[0.31%] 0.4-0.6:[0.27%] 0.6-0.8:[0.31%] 0.8-1.0:[46.76%]
(Train IMP:[2] fold:[0] spa:[4.96%] spw:[0.00%]) Epoch:[22/100] Loss:[0.3960] Train:[83.02] Test:[71.89] | Best Test:[77.74] at Epoch:[5] | 0-0.2:[40.49%] 0.2-0.4:[0.18%] 0.4-0.6:[0.14%] 0.6-0.8:[0.19%] 0.8-1.0:[59.00%]
(Train IMP:[2] fold:[0] spa:[4.96%] spw:[0.00%]) Epoch:[23/100] Loss:[0.3428] Train:[86.79] Test:[71.89] | Best Test:[77.74] at Epoch:[5] | 0-0.2:[47.57%] 0.2-0.4:[0.17%] 0.4-0.6:[0.15%] 0.6-0.8:[0.17%] 0.8-1.0:[51.95%]
(Train IMP:[2] fold:[0] spa:[4.96%] spw:[0.00%]) Epoch:[24/100] Loss:[0.2686] Train:[89.43] Test:[53.58] | Best Test:[77.74] at Epoch:[5] | 0-0.2:[40.95%] 0.2-0.4:[0.17%] 0.4-0.6:[0.14%] 0.6-0.8:[0.17%] 0.8-1.0:[58.57%]
(Train IMP:[2] fold:[0] spa:[4.96%] spw:[0.00%]) Epoch:[25/100] Loss:[0.2299] Train:[90.75] Test:[67.36] | Best Test:[77.74] at Epoch:[5] | 0-0.2:[41.13%] 0.2-0.4:[0.18%] 0.4-0.6:[0.14%] 0.6-0.8:[0.17%] 0.8-1.0:[58.39%]
(Train IMP:[2] fold:[0] spa:[4.96%] spw:[0.00%]) Epoch:[26/100] Loss:[0.2526] Train:[89.06] Test:[71.70] | Best Test:[77.74] at Epoch:[5] | 0-0.2:[43.14%] 0.2-0.4:[0.15%] 0.4-0.6:[0.12%] 0.6-0.8:[0.16%] 0.8-1.0:[56.42%]
(Train IMP:[2] fold:[0] spa:[4.96%] spw:[0.00%]) Epoch:[27/100] Loss:[0.2112] Train:[91.51] Test:[68.87] | Best Test:[77.74] at Epoch:[5] | 0-0.2:[44.65%] 0.2-0.4:[0.17%] 0.4-0.6:[0.14%] 0.6-0.8:[0.17%] 0.8-1.0:[54.87%]
(Train IMP:[2] fold:[0] spa:[4.96%] spw:[0.00%]) Epoch:[28/100] Loss:[0.2128] Train:[91.13] Test:[74.15] | Best Test:[77.74] at Epoch:[5] | 0-0.2:[46.28%] 0.2-0.4:[0.16%] 0.4-0.6:[0.13%] 0.6-0.8:[0.17%] 0.8-1.0:[53.26%]
(Train IMP:[2] fold:[0] spa:[4.96%] spw:[0.00%]) Epoch:[29/100] Loss:[0.1942] Train:[91.70] Test:[43.21] | Best Test:[77.74] at Epoch:[5] | 0-0.2:[55.42%] 0.2-0.4:[0.16%] 0.4-0.6:[0.15%] 0.6-0.8:[0.18%] 0.8-1.0:[44.09%]
(Train IMP:[2] fold:[0] spa:[4.96%] spw:[0.00%]) Epoch:[30/100] Loss:[0.1951] Train:[92.83] Test:[53.58] | Best Test:[77.74] at Epoch:[5] | 0-0.2:[51.81%] 0.2-0.4:[0.24%] 0.4-0.6:[0.20%] 0.6-0.8:[0.23%] 0.8-1.0:[47.52%]
(Train IMP:[2] fold:[0] spa:[4.96%] spw:[0.00%]) Epoch:[31/100] Loss:[0.2326] Train:[90.57] Test:[62.26] | Best Test:[77.74] at Epoch:[5] | 0-0.2:[46.40%] 0.2-0.4:[0.30%] 0.4-0.6:[0.23%] 0.6-0.8:[0.30%] 0.8-1.0:[52.77%]
(Train IMP:[2] fold:[0] spa:[4.96%] spw:[0.00%]) Epoch:[32/100] Loss:[0.1917] Train:[92.26] Test:[65.28] | Best Test:[77.74] at Epoch:[5] | 0-0.2:[47.40%] 0.2-0.4:[0.15%] 0.4-0.6:[0.14%] 0.6-0.8:[0.16%] 0.8-1.0:[52.14%]
(Train IMP:[2] fold:[0] spa:[4.96%] spw:[0.00%]) Epoch:[33/100] Loss:[0.2261] Train:[90.19] Test:[64.15] | Best Test:[77.74] at Epoch:[5] | 0-0.2:[40.72%] 0.2-0.4:[0.13%] 0.4-0.6:[0.10%] 0.6-0.8:[0.13%] 0.8-1.0:[58.91%]
(Train IMP:[2] fold:[0] spa:[4.96%] spw:[0.00%]) Epoch:[34/100] Loss:[0.1737] Train:[93.58] Test:[67.36] | Best Test:[77.74] at Epoch:[5] | 0-0.2:[36.58%] 0.2-0.4:[0.09%] 0.4-0.6:[0.08%] 0.6-0.8:[0.10%] 0.8-1.0:[63.15%]
(Train IMP:[2] fold:[0] spa:[4.96%] spw:[0.00%]) Epoch:[35/100] Loss:[0.1029] Train:[96.42] Test:[69.81] | Best Test:[77.74] at Epoch:[5] | 0-0.2:[35.42%] 0.2-0.4:[0.10%] 0.4-0.6:[0.08%] 0.6-0.8:[0.09%] 0.8-1.0:[64.31%]
(Train IMP:[2] fold:[0] spa:[4.96%] spw:[0.00%]) Epoch:[36/100] Loss:[0.1145] Train:[95.85] Test:[60.19] | Best Test:[77.74] at Epoch:[5] | 0-0.2:[35.94%] 0.2-0.4:[0.09%] 0.4-0.6:[0.08%] 0.6-0.8:[0.10%] 0.8-1.0:[63.79%]
(Train IMP:[2] fold:[0] spa:[4.96%] spw:[0.00%]) Epoch:[37/100] Loss:[0.0735] Train:[97.74] Test:[76.98] | Best Test:[77.74] at Epoch:[5] | 0-0.2:[36.41%] 0.2-0.4:[0.10%] 0.4-0.6:[0.08%] 0.6-0.8:[0.10%] 0.8-1.0:[63.32%]
(Train IMP:[2] fold:[0] spa:[4.96%] spw:[0.00%]) Epoch:[38/100] Loss:[0.0874] Train:[96.79] Test:[49.06] | Best Test:[77.74] at Epoch:[5] | 0-0.2:[38.47%] 0.2-0.4:[0.10%] 0.4-0.6:[0.09%] 0.6-0.8:[0.10%] 0.8-1.0:[61.24%]
(Train IMP:[2] fold:[0] spa:[4.96%] spw:[0.00%]) Epoch:[39/100] Loss:[0.0705] Train:[98.11] Test:[76.79] | Best Test:[77.74] at Epoch:[5] | 0-0.2:[34.73%] 0.2-0.4:[0.10%] 0.4-0.6:[0.08%] 0.6-0.8:[0.10%] 0.8-1.0:[64.99%]
(Train IMP:[2] fold:[0] spa:[4.96%] spw:[0.00%]) Epoch:[40/100] Loss:[0.1059] Train:[97.17] Test:[70.94] | Best Test:[77.74] at Epoch:[5] | 0-0.2:[28.88%] 0.2-0.4:[0.10%] 0.4-0.6:[0.08%] 0.6-0.8:[0.09%] 0.8-1.0:[70.85%]
(Train IMP:[2] fold:[0] spa:[4.96%] spw:[0.00%]) Epoch:[41/100] Loss:[0.1068] Train:[95.85] Test:[72.26] | Best Test:[77.74] at Epoch:[5] | 0-0.2:[31.93%] 0.2-0.4:[0.10%] 0.4-0.6:[0.09%] 0.6-0.8:[0.11%] 0.8-1.0:[67.78%]
(Train IMP:[2] fold:[0] spa:[4.96%] spw:[0.00%]) Epoch:[42/100] Loss:[0.1247] Train:[94.91] Test:[43.58] | Best Test:[77.74] at Epoch:[5] | 0-0.2:[40.80%] 0.2-0.4:[0.10%] 0.4-0.6:[0.08%] 0.6-0.8:[0.10%] 0.8-1.0:[58.91%]
(Train IMP:[2] fold:[0] spa:[4.96%] spw:[0.00%]) Epoch:[43/100] Loss:[0.0930] Train:[96.42] Test:[63.40] | Best Test:[77.74] at Epoch:[5] | 0-0.2:[48.18%] 0.2-0.4:[0.09%] 0.4-0.6:[0.07%] 0.6-0.8:[0.09%] 0.8-1.0:[51.56%]
(Train IMP:[2] fold:[0] spa:[4.96%] spw:[0.00%]) Epoch:[44/100] Loss:[0.1283] Train:[94.91] Test:[60.00] | Best Test:[77.74] at Epoch:[5] | 0-0.2:[47.20%] 0.2-0.4:[0.11%] 0.4-0.6:[0.09%] 0.6-0.8:[0.11%] 0.8-1.0:[52.48%]
(Train IMP:[2] fold:[0] spa:[4.96%] spw:[0.00%]) Epoch:[45/100] Loss:[0.1347] Train:[96.04] Test:[63.77] | Best Test:[77.74] at Epoch:[5] | 0-0.2:[33.96%] 0.2-0.4:[0.18%] 0.4-0.6:[0.14%] 0.6-0.8:[0.17%] 0.8-1.0:[65.55%]
(Train IMP:[2] fold:[0] spa:[4.96%] spw:[0.00%]) Epoch:[46/100] Loss:[0.0930] Train:[96.42] Test:[75.09] | Best Test:[77.74] at Epoch:[5] | 0-0.2:[32.37%] 0.2-0.4:[0.18%] 0.4-0.6:[0.14%] 0.6-0.8:[0.17%] 0.8-1.0:[67.14%]
(Train IMP:[2] fold:[0] spa:[4.96%] spw:[0.00%]) Epoch:[47/100] Loss:[0.1104] Train:[96.23] Test:[68.87] | Best Test:[77.74] at Epoch:[5] | 0-0.2:[38.75%] 0.2-0.4:[0.12%] 0.4-0.6:[0.10%] 0.6-0.8:[0.13%] 0.8-1.0:[60.91%]
(Train IMP:[2] fold:[0] spa:[4.96%] spw:[0.00%]) Epoch:[48/100] Loss:[0.0637] Train:[97.74] Test:[73.58] | Best Test:[77.74] at Epoch:[5] | 0-0.2:[39.11%] 0.2-0.4:[0.10%] 0.4-0.6:[0.08%] 0.6-0.8:[0.09%] 0.8-1.0:[60.61%]
(Train IMP:[2] fold:[0] spa:[4.96%] spw:[0.00%]) Epoch:[49/100] Loss:[0.0558] Train:[97.92] Test:[70.75] | Best Test:[77.74] at Epoch:[5] | 0-0.2:[29.39%] 0.2-0.4:[0.10%] 0.4-0.6:[0.08%] 0.6-0.8:[0.10%] 0.8-1.0:[70.33%]
(Train IMP:[2] fold:[0] spa:[4.96%] spw:[0.00%]) Epoch:[50/100] Loss:[0.0973] Train:[96.60] Test:[72.45] | Best Test:[77.74] at Epoch:[5] | 0-0.2:[29.01%] 0.2-0.4:[0.11%] 0.4-0.6:[0.09%] 0.6-0.8:[0.11%] 0.8-1.0:[70.69%]
(Train IMP:[2] fold:[0] spa:[4.96%] spw:[0.00%]) Epoch:[51/100] Loss:[0.0827] Train:[97.17] Test:[59.06] | Best Test:[77.74] at Epoch:[5] | 0-0.2:[29.79%] 0.2-0.4:[0.10%] 0.4-0.6:[0.09%] 0.6-0.8:[0.10%] 0.8-1.0:[69.92%]
(Train IMP:[2] fold:[0] spa:[4.96%] spw:[0.00%]) Epoch:[52/100] Loss:[0.0721] Train:[97.17] Test:[72.83] | Best Test:[77.74] at Epoch:[5] | 0-0.2:[25.15%] 0.2-0.4:[0.10%] 0.4-0.6:[0.08%] 0.6-0.8:[0.10%] 0.8-1.0:[74.57%]
(Train IMP:[2] fold:[0] spa:[4.96%] spw:[0.00%]) Epoch:[53/100] Loss:[0.0560] Train:[98.11] Test:[72.45] | Best Test:[77.74] at Epoch:[5] | 0-0.2:[23.98%] 0.2-0.4:[0.10%] 0.4-0.6:[0.08%] 0.6-0.8:[0.09%] 0.8-1.0:[75.75%]
(Train IMP:[2] fold:[0] spa:[4.96%] spw:[0.00%]) Epoch:[54/100] Loss:[0.0393] Train:[99.25] Test:[75.85] | Best Test:[77.74] at Epoch:[5] | 0-0.2:[11.51%] 0.2-0.4:[0.08%] 0.4-0.6:[0.06%] 0.6-0.8:[0.06%] 0.8-1.0:[88.30%]
(Train IMP:[2] fold:[0] spa:[4.96%] spw:[0.00%]) Epoch:[55/100] Loss:[0.0681] Train:[97.36] Test:[71.32] | Best Test:[77.74] at Epoch:[5] | 0-0.2:[4.88%] 0.2-0.4:[0.04%] 0.4-0.6:[0.04%] 0.6-0.8:[0.04%] 0.8-1.0:[95.00%]
(Train IMP:[2] fold:[0] spa:[4.96%] spw:[0.00%]) Epoch:[56/100] Loss:[0.0490] Train:[98.30] Test:[57.92] | Best Test:[77.74] at Epoch:[5] | 0-0.2:[5.08%] 0.2-0.4:[0.05%] 0.4-0.6:[0.04%] 0.6-0.8:[0.05%] 0.8-1.0:[94.78%]
(Train IMP:[2] fold:[0] spa:[4.96%] spw:[0.00%]) Epoch:[57/100] Loss:[0.0235] Train:[99.25] Test:[73.21] | Best Test:[77.74] at Epoch:[5] | 0-0.2:[0.03%] 0.2-0.4:[0.00%] 0.4-0.6:[0.00%] 0.6-0.8:[0.00%] 0.8-1.0:[99.96%]
(Train IMP:[2] fold:[0] spa:[4.96%] spw:[0.00%]) Epoch:[58/100] Loss:[0.0233] Train:[98.87] Test:[47.36] | Best Test:[77.74] at Epoch:[5] | 0-0.2:[0.00%] 0.2-0.4:[0.00%] 0.4-0.6:[0.00%] 0.6-0.8:[0.00%] 0.8-1.0:[100.00%]
(Train IMP:[2] fold:[0] spa:[4.96%] spw:[0.00%]) Epoch:[59/100] Loss:[0.0574] Train:[97.74] Test:[64.34] | Best Test:[77.74] at Epoch:[5] | 0-0.2:[0.00%] 0.2-0.4:[0.00%] 0.4-0.6:[0.00%] 0.6-0.8:[0.00%] 0.8-1.0:[100.00%]
(Train IMP:[2] fold:[0] spa:[4.96%] spw:[0.00%]) Epoch:[60/100] Loss:[0.0649] Train:[97.92] Test:[66.98] | Best Test:[77.74] at Epoch:[5] | 0-0.2:[0.00%] 0.2-0.4:[0.00%] 0.4-0.6:[0.00%] 0.6-0.8:[0.00%] 0.8-1.0:[100.00%]
(Train IMP:[2] fold:[0] spa:[4.96%] spw:[0.00%]) Epoch:[61/100] Loss:[0.1488] Train:[95.09] Test:[51.70] | Best Test:[77.74] at Epoch:[5] | 0-0.2:[0.00%] 0.2-0.4:[0.00%] 0.4-0.6:[0.00%] 0.6-0.8:[0.00%] 0.8-1.0:[100.00%]
(Train IMP:[2] fold:[0] spa:[4.96%] spw:[0.00%]) Epoch:[62/100] Loss:[0.1133] Train:[96.60] Test:[65.09] | Best Test:[77.74] at Epoch:[5] | 0-0.2:[0.00%] 0.2-0.4:[0.00%] 0.4-0.6:[0.00%] 0.6-0.8:[0.00%] 0.8-1.0:[100.00%]
(Train IMP:[2] fold:[0] spa:[4.96%] spw:[0.00%]) Epoch:[63/100] Loss:[0.0482] Train:[98.68] Test:[67.36] | Best Test:[77.74] at Epoch:[5] | 0-0.2:[0.00%] 0.2-0.4:[0.00%] 0.4-0.6:[0.00%] 0.6-0.8:[0.00%] 0.8-1.0:[100.00%]
(Train IMP:[2] fold:[0] spa:[4.96%] spw:[0.00%]) Epoch:[64/100] Loss:[0.0598] Train:[98.30] Test:[63.02] | Best Test:[77.74] at Epoch:[5] | 0-0.2:[0.00%] 0.2-0.4:[0.00%] 0.4-0.6:[0.00%] 0.6-0.8:[0.00%] 0.8-1.0:[100.00%]
(Train IMP:[2] fold:[0] spa:[4.96%] spw:[0.00%]) Epoch:[65/100] Loss:[0.0858] Train:[97.36] Test:[51.32] | Best Test:[77.74] at Epoch:[5] | 0-0.2:[0.00%] 0.2-0.4:[0.00%] 0.4-0.6:[0.00%] 0.6-0.8:[0.00%] 0.8-1.0:[100.00%]
(Train IMP:[2] fold:[0] spa:[4.96%] spw:[0.00%]) Epoch:[66/100] Loss:[0.0366] Train:[98.87] Test:[75.09] | Best Test:[77.74] at Epoch:[5] | 0-0.2:[0.00%] 0.2-0.4:[0.00%] 0.4-0.6:[0.00%] 0.6-0.8:[0.00%] 0.8-1.0:[100.00%]
(Train IMP:[2] fold:[0] spa:[4.96%] spw:[0.00%]) Epoch:[67/100] Loss:[0.0260] Train:[99.06] Test:[68.11] | Best Test:[77.74] at Epoch:[5] | 0-0.2:[0.00%] 0.2-0.4:[0.00%] 0.4-0.6:[0.00%] 0.6-0.8:[0.00%] 0.8-1.0:[100.00%]
(Train IMP:[2] fold:[0] spa:[4.96%] spw:[0.00%]) Epoch:[68/100] Loss:[0.0150] Train:[99.43] Test:[71.32] | Best Test:[77.74] at Epoch:[5] | 0-0.2:[0.00%] 0.2-0.4:[0.00%] 0.4-0.6:[0.00%] 0.6-0.8:[0.00%] 0.8-1.0:[100.00%]
(Train IMP:[2] fold:[0] spa:[4.96%] spw:[0.00%]) Epoch:[69/100] Loss:[0.0475] Train:[97.92] Test:[50.75] | Best Test:[77.74] at Epoch:[5] | 0-0.2:[0.00%] 0.2-0.4:[0.00%] 0.4-0.6:[0.00%] 0.6-0.8:[0.00%] 0.8-1.0:[100.00%]
(Train IMP:[2] fold:[0] spa:[4.96%] spw:[0.00%]) Epoch:[70/100] Loss:[0.0255] Train:[99.25] Test:[73.40] | Best Test:[77.74] at Epoch:[5] | 0-0.2:[0.00%] 0.2-0.4:[0.00%] 0.4-0.6:[0.00%] 0.6-0.8:[0.00%] 0.8-1.0:[100.00%]
(Train IMP:[2] fold:[0] spa:[4.96%] spw:[0.00%]) Epoch:[71/100] Loss:[0.0808] Train:[96.79] Test:[69.43] | Best Test:[77.74] at Epoch:[5] | 0-0.2:[0.00%] 0.2-0.4:[0.00%] 0.4-0.6:[0.00%] 0.6-0.8:[0.00%] 0.8-1.0:[100.00%]
(Train IMP:[2] fold:[0] spa:[4.96%] spw:[0.00%]) Epoch:[72/100] Loss:[0.0293] Train:[98.87] Test:[73.40] | Best Test:[77.74] at Epoch:[5] | 0-0.2:[0.00%] 0.2-0.4:[0.00%] 0.4-0.6:[0.00%] 0.6-0.8:[0.00%] 0.8-1.0:[100.00%]
(Train IMP:[2] fold:[0] spa:[4.96%] spw:[0.00%]) Epoch:[73/100] Loss:[0.0188] Train:[99.43] Test:[68.11] | Best Test:[77.74] at Epoch:[5] | 0-0.2:[0.00%] 0.2-0.4:[0.00%] 0.4-0.6:[0.00%] 0.6-0.8:[0.00%] 0.8-1.0:[100.00%]
(Train IMP:[2] fold:[0] spa:[4.96%] spw:[0.00%]) Epoch:[74/100] Loss:[0.0233] Train:[99.43] Test:[69.81] | Best Test:[77.74] at Epoch:[5] | 0-0.2:[0.00%] 0.2-0.4:[0.00%] 0.4-0.6:[0.00%] 0.6-0.8:[0.00%] 0.8-1.0:[100.00%]
(Train IMP:[2] fold:[0] spa:[4.96%] spw:[0.00%]) Epoch:[75/100] Loss:[0.0153] Train:[99.43] Test:[56.98] | Best Test:[77.74] at Epoch:[5] | 0-0.2:[0.00%] 0.2-0.4:[0.00%] 0.4-0.6:[0.00%] 0.6-0.8:[0.00%] 0.8-1.0:[100.00%]
(Train IMP:[2] fold:[0] spa:[4.96%] spw:[0.00%]) Epoch:[76/100] Loss:[0.0153] Train:[99.62] Test:[74.53] | Best Test:[77.74] at Epoch:[5] | 0-0.2:[0.00%] 0.2-0.4:[0.00%] 0.4-0.6:[0.00%] 0.6-0.8:[0.00%] 0.8-1.0:[100.00%]
(Train IMP:[2] fold:[0] spa:[4.96%] spw:[0.00%]) Epoch:[77/100] Loss:[0.0134] Train:[99.62] Test:[69.43] | Best Test:[77.74] at Epoch:[5] | 0-0.2:[0.00%] 0.2-0.4:[0.00%] 0.4-0.6:[0.00%] 0.6-0.8:[0.00%] 0.8-1.0:[100.00%]
(Train IMP:[2] fold:[0] spa:[4.96%] spw:[0.00%]) Epoch:[78/100] Loss:[0.0156] Train:[99.62] Test:[69.06] | Best Test:[77.74] at Epoch:[5] | 0-0.2:[0.00%] 0.2-0.4:[0.00%] 0.4-0.6:[0.00%] 0.6-0.8:[0.00%] 0.8-1.0:[100.00%]
(Train IMP:[2] fold:[0] spa:[4.96%] spw:[0.00%]) Epoch:[79/100] Loss:[0.0107] Train:[99.43] Test:[71.89] | Best Test:[77.74] at Epoch:[5] | 0-0.2:[0.00%] 0.2-0.4:[0.00%] 0.4-0.6:[0.00%] 0.6-0.8:[0.00%] 0.8-1.0:[100.00%]
(Train IMP:[2] fold:[0] spa:[4.96%] spw:[0.00%]) Epoch:[80/100] Loss:[0.0272] Train:[99.43] Test:[64.53] | Best Test:[77.74] at Epoch:[5] | 0-0.2:[0.00%] 0.2-0.4:[0.00%] 0.4-0.6:[0.00%] 0.6-0.8:[0.00%] 0.8-1.0:[100.00%]
(Train IMP:[2] fold:[0] spa:[4.96%] spw:[0.00%]) Epoch:[81/100] Loss:[0.0252] Train:[98.87] Test:[65.47] | Best Test:[77.74] at Epoch:[5] | 0-0.2:[0.00%] 0.2-0.4:[0.00%] 0.4-0.6:[0.00%] 0.6-0.8:[0.00%] 0.8-1.0:[100.00%]
(Train IMP:[2] fold:[0] spa:[4.96%] spw:[0.00%]) Epoch:[82/100] Loss:[0.0534] Train:[98.11] Test:[74.91] | Best Test:[77.74] at Epoch:[5] | 0-0.2:[0.00%] 0.2-0.4:[0.00%] 0.4-0.6:[0.00%] 0.6-0.8:[0.00%] 0.8-1.0:[100.00%]
(Train IMP:[2] fold:[0] spa:[4.96%] spw:[0.00%]) Epoch:[83/100] Loss:[0.0252] Train:[98.87] Test:[69.62] | Best Test:[77.74] at Epoch:[5] | 0-0.2:[0.00%] 0.2-0.4:[0.00%] 0.4-0.6:[0.00%] 0.6-0.8:[0.00%] 0.8-1.0:[100.00%]
(Train IMP:[2] fold:[0] spa:[4.96%] spw:[0.00%]) Epoch:[84/100] Loss:[0.0329] Train:[99.06] Test:[69.81] | Best Test:[77.74] at Epoch:[5] | 0-0.2:[0.00%] 0.2-0.4:[0.00%] 0.4-0.6:[0.00%] 0.6-0.8:[0.00%] 0.8-1.0:[100.00%]
(Train IMP:[2] fold:[0] spa:[4.96%] spw:[0.00%]) Epoch:[85/100] Loss:[0.0171] Train:[99.62] Test:[64.15] | Best Test:[77.74] at Epoch:[5] | 0-0.2:[0.00%] 0.2-0.4:[0.00%] 0.4-0.6:[0.00%] 0.6-0.8:[0.00%] 0.8-1.0:[100.00%]
(Train IMP:[2] fold:[0] spa:[4.96%] spw:[0.00%]) Epoch:[86/100] Loss:[0.0152] Train:[99.25] Test:[69.06] | Best Test:[77.74] at Epoch:[5] | 0-0.2:[0.00%] 0.2-0.4:[0.00%] 0.4-0.6:[0.00%] 0.6-0.8:[0.00%] 0.8-1.0:[100.00%]
(Train IMP:[2] fold:[0] spa:[4.96%] spw:[0.00%]) Epoch:[87/100] Loss:[0.0123] Train:[99.06] Test:[71.51] | Best Test:[77.74] at Epoch:[5] | 0-0.2:[0.00%] 0.2-0.4:[0.00%] 0.4-0.6:[0.00%] 0.6-0.8:[0.00%] 0.8-1.0:[100.00%]
(Train IMP:[2] fold:[0] spa:[4.96%] spw:[0.00%]) Epoch:[88/100] Loss:[0.0223] Train:[98.87] Test:[59.25] | Best Test:[77.74] at Epoch:[5] | 0-0.2:[0.00%] 0.2-0.4:[0.00%] 0.4-0.6:[0.00%] 0.6-0.8:[0.00%] 0.8-1.0:[100.00%]
(Train IMP:[2] fold:[0] spa:[4.96%] spw:[0.00%]) Epoch:[89/100] Loss:[0.0484] Train:[98.30] Test:[71.70] | Best Test:[77.74] at Epoch:[5] | 0-0.2:[0.00%] 0.2-0.4:[0.00%] 0.4-0.6:[0.00%] 0.6-0.8:[0.00%] 0.8-1.0:[100.00%]
(Train IMP:[2] fold:[0] spa:[4.96%] spw:[0.00%]) Epoch:[90/100] Loss:[0.0317] Train:[99.06] Test:[71.51] | Best Test:[77.74] at Epoch:[5] | 0-0.2:[0.00%] 0.2-0.4:[0.00%] 0.4-0.6:[0.00%] 0.6-0.8:[0.00%] 0.8-1.0:[100.00%]
(Train IMP:[2] fold:[0] spa:[4.96%] spw:[0.00%]) Epoch:[91/100] Loss:[0.0370] Train:[98.49] Test:[45.09] | Best Test:[77.74] at Epoch:[5] | 0-0.2:[0.00%] 0.2-0.4:[0.00%] 0.4-0.6:[0.00%] 0.6-0.8:[0.00%] 0.8-1.0:[100.00%]
(Train IMP:[2] fold:[0] spa:[4.96%] spw:[0.00%]) Epoch:[92/100] Loss:[0.0377] Train:[98.87] Test:[72.26] | Best Test:[77.74] at Epoch:[5] | 0-0.2:[0.00%] 0.2-0.4:[0.00%] 0.4-0.6:[0.00%] 0.6-0.8:[0.00%] 0.8-1.0:[100.00%]
(Train IMP:[2] fold:[0] spa:[4.96%] spw:[0.00%]) Epoch:[93/100] Loss:[0.0115] Train:[99.62] Test:[70.94] | Best Test:[77.74] at Epoch:[5] | 0-0.2:[0.00%] 0.2-0.4:[0.00%] 0.4-0.6:[0.00%] 0.6-0.8:[0.00%] 0.8-1.0:[100.00%]
(Train IMP:[2] fold:[0] spa:[4.96%] spw:[0.00%]) Epoch:[94/100] Loss:[0.0038] Train:[100.00] Test:[71.32] | Best Test:[77.74] at Epoch:[5] | 0-0.2:[0.00%] 0.2-0.4:[0.00%] 0.4-0.6:[0.00%] 0.6-0.8:[0.00%] 0.8-1.0:[100.00%]
(Train IMP:[2] fold:[0] spa:[4.96%] spw:[0.00%]) Epoch:[95/100] Loss:[0.0092] Train:[99.62] Test:[69.43] | Best Test:[77.74] at Epoch:[5] | 0-0.2:[0.00%] 0.2-0.4:[0.00%] 0.4-0.6:[0.00%] 0.6-0.8:[0.00%] 0.8-1.0:[100.00%]
(Train IMP:[2] fold:[0] spa:[4.96%] spw:[0.00%]) Epoch:[96/100] Loss:[0.0033] Train:[100.00] Test:[73.96] | Best Test:[77.74] at Epoch:[5] | 0-0.2:[0.00%] 0.2-0.4:[0.00%] 0.4-0.6:[0.00%] 0.6-0.8:[0.00%] 0.8-1.0:[100.00%]
(Train IMP:[2] fold:[0] spa:[4.96%] spw:[0.00%]) Epoch:[97/100] Loss:[0.0017] Train:[100.00] Test:[74.15] | Best Test:[77.74] at Epoch:[5] | 0-0.2:[0.00%] 0.2-0.4:[0.00%] 0.4-0.6:[0.00%] 0.6-0.8:[0.00%] 0.8-1.0:[100.00%]
(Train IMP:[2] fold:[0] spa:[4.96%] spw:[0.00%]) Epoch:[98/100] Loss:[0.0016] Train:[100.00] Test:[71.51] | Best Test:[77.74] at Epoch:[5] | 0-0.2:[0.00%] 0.2-0.4:[0.00%] 0.4-0.6:[0.00%] 0.6-0.8:[0.00%] 0.8-1.0:[100.00%]
(Train IMP:[2] fold:[0] spa:[4.96%] spw:[0.00%]) Epoch:[99/100] Loss:[0.0024] Train:[100.00] Test:[71.13] | Best Test:[77.74] at Epoch:[5] | 0-0.2:[0.00%] 0.2-0.4:[0.00%] 0.4-0.6:[0.00%] 0.6-0.8:[0.00%] 0.8-1.0:[100.00%]
(Train IMP:[2] fold:[0] spa:[4.96%] spw:[0.00%]) Epoch:[100/100] Loss:[0.0010] Train:[100.00] Test:[72.26] | Best Test:[77.74] at Epoch:[5] | 0-0.2:[0.00%] 0.2-0.4:[0.00%] 0.4-0.6:[0.00%] 0.6-0.8:[0.00%] 0.8-1.0:[100.00%]
INFO: Weight Sparsity [0.0000%] 
(Train IMP:[2] fold:[1] spa:[4.96%] spw:[0.00%]) Epoch:[1/100] Loss:[0.5501] Train:[72.83] Test:[43.40] | Best Test:[43.40] at Epoch:[1] | 0-0.2:[19.77%] 0.2-0.4:[26.51%] 0.4-0.6:[28.68%] 0.6-0.8:[14.89%] 0.8-1.0:[10.15%]
(Train IMP:[2] fold:[1] spa:[4.96%] spw:[0.00%]) Epoch:[2/100] Loss:[0.4782] Train:[78.68] Test:[43.21] | Best Test:[43.40] at Epoch:[1] | 0-0.2:[22.16%] 0.2-0.4:[12.42%] 0.4-0.6:[13.72%] 0.6-0.8:[17.42%] 0.8-1.0:[34.28%]
(Train IMP:[2] fold:[1] spa:[4.96%] spw:[0.00%]) Epoch:[3/100] Loss:[0.4495] Train:[80.94] Test:[64.91] | Best Test:[64.91] at Epoch:[3] | 0-0.2:[33.47%] 0.2-0.4:[8.30%] 0.4-0.6:[7.26%] 0.6-0.8:[8.94%] 0.8-1.0:[42.02%]
(Train IMP:[2] fold:[1] spa:[4.96%] spw:[0.00%]) Epoch:[4/100] Loss:[0.4353] Train:[79.81] Test:[76.60] | Best Test:[76.60] at Epoch:[4] | 0-0.2:[26.20%] 0.2-0.4:[6.31%] 0.4-0.6:[6.02%] 0.6-0.8:[8.03%] 0.8-1.0:[53.44%]
(Train IMP:[2] fold:[1] spa:[4.96%] spw:[0.00%]) Epoch:[5/100] Loss:[0.4088] Train:[82.45] Test:[62.64] | Best Test:[76.60] at Epoch:[4] | 0-0.2:[27.04%] 0.2-0.4:[3.14%] 0.4-0.6:[2.79%] 0.6-0.8:[3.60%] 0.8-1.0:[63.43%]
(Train IMP:[2] fold:[1] spa:[4.96%] spw:[0.00%]) Epoch:[6/100] Loss:[0.3660] Train:[82.83] Test:[56.98] | Best Test:[76.60] at Epoch:[4] | 0-0.2:[26.89%] 0.2-0.4:[3.52%] 0.4-0.6:[3.10%] 0.6-0.8:[4.14%] 0.8-1.0:[62.35%]
(Train IMP:[2] fold:[1] spa:[4.96%] spw:[0.00%]) Epoch:[7/100] Loss:[0.4133] Train:[82.08] Test:[54.72] | Best Test:[76.60] at Epoch:[4] | 0-0.2:[18.82%] 0.2-0.4:[3.98%] 0.4-0.6:[4.02%] 0.6-0.8:[6.14%] 0.8-1.0:[67.04%]
